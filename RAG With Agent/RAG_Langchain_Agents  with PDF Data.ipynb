{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Install required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-pinecone"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.7.21 requires urllib3<2, but you have urllib3 2.2.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading langchain_pinecone-0.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.5 (from langchain-pinecone)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-pinecone) (0.2.23)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-pinecone) (1.25.2)\n",
      "Collecting pinecone-client<6.0.0,>=5.0.0 (from langchain-pinecone)\n",
      "  Downloading pinecone_client-5.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (1.9.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.7.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (8.2.3)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2023.7.22)\n",
      "Collecting pinecone-plugin-inference==1.0.2 (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone)\n",
      "  Downloading pinecone_plugin_inference-1.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (4.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.18.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (0.4.4)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (3.2.0)\n",
      "Downloading langchain_pinecone-0.1.3-py3-none-any.whl (10 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/370.8 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/370.8 kB 495.5 kB/s eta 0:00:01\n",
      "   ------ -------------------------------- 61.4/370.8 kB 550.5 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 71.7/370.8 kB 438.9 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 71.7/370.8 kB 438.9 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 122.9/370.8 kB 450.6 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/370.8 kB 449.7 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 153.6/370.8 kB 399.3 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 174.1/370.8 kB 420.1 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 194.6/370.8 kB 421.8 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 204.8/370.8 kB 377.8 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 204.8/370.8 kB 377.8 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 235.5/370.8 kB 369.9 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 235.5/370.8 kB 369.9 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 256.0/370.8 kB 366.3 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 256.0/370.8 kB 366.3 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 276.5/370.8 kB 334.5 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 276.5/370.8 kB 334.5 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 286.7/370.8 kB 310.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 286.7/370.8 kB 310.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 286.7/370.8 kB 310.7 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 307.2/370.8 kB 283.9 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 307.2/370.8 kB 283.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 317.4/370.8 kB 265.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 317.4/370.8 kB 265.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 337.9/370.8 kB 262.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 337.9/370.8 kB 262.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 337.9/370.8 kB 262.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 370.8/370.8 kB 200.8 kB/s eta 0:00:00\n",
      "Downloading pinecone_client-5.0.0-py3-none-any.whl (244 kB)\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/244.8 kB 65.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 30.7/244.8 kB 65.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 30.7/244.8 kB 65.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 30.7/244.8 kB 65.6 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   ----------------- --------------------- 112.6/244.8 kB 42.0 kB/s eta 0:00:04\n",
      "   ----------------- --------------------- 112.6/244.8 kB 42.0 kB/s eta 0:00:04\n",
      "   ----------------- --------------------- 112.6/244.8 kB 42.0 kB/s eta 0:00:04\n",
      "   ----------------- --------------------- 112.6/244.8 kB 42.0 kB/s eta 0:00:04\n",
      "   ------------------- ------------------- 122.9/244.8 kB 42.6 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 122.9/244.8 kB 42.6 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 122.9/244.8 kB 42.6 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 122.9/244.8 kB 42.6 kB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 143.4/244.8 kB 47.1 kB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 143.4/244.8 kB 47.1 kB/s eta 0:00:03\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   --------------------------- ----------- 174.1/244.8 kB 47.7 kB/s eta 0:00:02\n",
      "   --------------------------- ----------- 174.1/244.8 kB 47.7 kB/s eta 0:00:02\n",
      "   --------------------------- ----------- 174.1/244.8 kB 47.7 kB/s eta 0:00:02\n",
      "   --------------------------- ----------- 174.1/244.8 kB 47.7 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 184.3/244.8 kB 47.8 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 184.3/244.8 kB 47.8 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 184.3/244.8 kB 47.8 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 184.3/244.8 kB 47.8 kB/s eta 0:00:02\n",
      "   -------------------------------- ------ 204.8/244.8 kB 50.8 kB/s eta 0:00:01\n",
      "   -------------------------------- ------ 204.8/244.8 kB 50.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 235.5/244.8 kB 50.2 kB/s eta 0:00:01\n",
      "   --------------------------------------- 244.8/244.8 kB 51.9 kB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_inference-1.0.2-py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 112.6/117.6 kB 61.2 kB/s eta 0:00:01\n",
      "   --------------------------------------- 117.6/117.6 kB 61.9 kB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, aiohttp, pinecone-plugin-inference, pinecone-client, langchain-pinecone\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.6\n",
      "    Uninstalling aiohttp-3.8.6:\n",
      "      Successfully uninstalled aiohttp-3.8.6\n",
      "Successfully installed aiohttp-3.9.5 langchain-pinecone-0.1.3 pinecone-client-5.0.0 pinecone-plugin-inference-1.0.2 pinecone-plugin-interface-0.0.7\n",
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-0.1.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
      "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.3,>=0.2.24 (from langchain-groq)\n",
      "  Downloading langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (2.7.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.10.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (8.2.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.24->langchain-groq) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-groq) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-groq) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-groq) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-groq) (2.2.2)\n",
      "Downloading langchain_groq-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.5 kB ? eta -:--:--\n",
      "   --------------- ----------------------- 41.0/103.5 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 103.5/103.5 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.2.24-py3-none-any.whl (377 kB)\n",
      "   ---------------------------------------- 0.0/377.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/377.3 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 143.4/377.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 184.3/377.3 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 204.8/377.3 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 256.0/377.3 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 348.2/377.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 377.3/377.3 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: groq, langchain-core, langchain-groq\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.23\n",
      "    Uninstalling langchain-core-0.2.23:\n",
      "      Successfully uninstalled langchain-core-0.2.23\n",
      "Successfully installed groq-0.9.0 langchain-core-0.2.24 langchain-groq-0.1.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.7.21 requires urllib3<2, but you have urllib3 2.2.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain python-dotenv tiktoken langchain-pinecone openai langchain-openai langchainhub ipykernel pandas langchain-groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd6r8E3wY8hV"
   },
   "source": [
    "# Import Packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "92jiBtwGBSYf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Temp\\ipykernel_16752\\3698905458.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from uuid import uuid4\n",
    "# from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "# LANGCHAIN\n",
    "import langchain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# VECTOR STORE\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# AGENTS\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import AgentExecutor, Tool, AgentType\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "from langchain import hub "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyAXLKhotfpoaEY_Co69uBQUoXOQwPsP-Vc'\n",
    "os.environ['COHERE_API_KEY'] = 'vRhoY37DN64h1LJ4spzSxSrOMTry8udp2T4satyP'\n",
    "os.environ['PINECONE_API_KEY'] = '080aa9ac-3af8-4cfb-b40d-b88fe5e0ac10'\n",
    "os.environ['TAVILY_API_KEY'] = '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'\n",
    "\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "import google.generativeai as genai\n",
    "GOOGLE_API_KEY= os.getenv('GOOGLE_API_KEY')  \n",
    "genai.configure(api_key=GOOGLE_API_KEY) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yAeKxERZKFS"
   },
   "source": [
    "# Load Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjU_B_teau09"
   },
   "source": [
    "There are several Document Loaders in the LangChain library depending on the type of file to be used. The most common ones include CSV, HTML, JSON, Markdown, File Directory or Microsoft Office formats. The complete list can be found [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/office_file/).\n",
    "\n",
    "However, there is a more extensive [list](https://python.langchain.com/docs/integrations/document_loaders/google_drive/), where you can load directly from Google Cloud, Notion, Youtube or many other services.\n",
    "\n",
    "We will be using a csv file, so we will use the CSVLoader. Below you can find the code to load the file. As arguments we are using:\n",
    "\n",
    "- **file path**\n",
    "- **source column**: indicates the column in the CSV file that contains the primary data of interest, transcript\n",
    "- **metadata columns**: list of column names that contain additional information (metadata) about each entry in the transcript\n",
    "\n",
    "Loading the data in this way will benefit our RAG pipeline. The benefits of metadata are listed further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyEihDI5Qzq2",
    "outputId": "088e416e-dc38-47cf-d668-2dec6b8e33e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load Documents\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"./UET_Lahore.pdf\") # Load the document\n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GU89RoE-c7wN"
   },
   "source": [
    "The **PDFLoader** allows us to upload a PDF file and there are some arguments that can further enhance the pipeline, mainly metadata.\n",
    "\n",
    "**Benefits of Metadata:**\n",
    "\n",
    "- Enhanced Retrieval: Metadata provides additional context about the primary data, which significantly improves the accuracy and relevance of the information retrieved. This is particularly important in RAG, where the goal is to retrieve data that is relevant to a user's query and provide it as context for the LLM. By incorporating metadata, the system can better understand the nuances of the query and retrieve data that is more likely to be relevant to the user's needs. For example, knowing the author, title, and publication_date can offer insights into the content of the document.\n",
    "\n",
    "- Improved Response Generation: The addition of metadata to the data chunks being processed by the LLM allows for a more nuanced and context-aware retrieval process. This leads to higher quality outcomes in response generation, as the LLM is able to draw upon a richer understanding of the context in which the data is being retrieved.\n",
    "\n",
    "- Reduced Hallucinations: By grounding the LLM's output on relevant, external knowledge, RAG attempts to mitigate the risk of responding with incorrect or fabricated information (hallucinations). The use of metadata helps to ensure that the responses generated by the LLM are based on accurate and relevant information, rather than simply relying on static training data.\n",
    "\n",
    "- Domain-Specific Responses: Metadata can be used to provide domain-specific, relevant responses tailored to an organization's proprietary or domain-specific data. This is particularly important in applications where the LLM needs to provide responses that are specific to a particular domain or industry.\n",
    "\n",
    "- Efficiency and Cost-Effectiveness: RAG is a simple and cost-effective approach to customizing LLMs with domain-specific data. By leveraging metadata, organizations can deploy RAG without needing to customize the model, which is especially beneficial when models need to be updated frequently with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4yk-rKc8sEq"
   },
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xijya_O0d2FJ"
   },
   "source": [
    "The **Vector Store Index** is a tool that embeds your documents into vector representations. When you want to search through these embeddings, your query is also converted into a vector embedding. Then, the Vector Store Index performs a mathematical operation to rank all the document embeddings based on how semantically similar they are to your query embedding.\n",
    "\n",
    "The key steps are:\n",
    "- Embedding your documents into vectors\n",
    "- Turning your search query into a vector\n",
    "- Comparing the query vector to all the document vectors\n",
    "- Ranking the document vectors by their similarity to the query vector\n",
    "- Returning the most relevant documents based on this ranking\n",
    "\n",
    "This allows you to search your document collection in a semantic, meaning-based way, rather than just looking for exact keyword matches.\n",
    "\n",
    "To understand the process of vector search, we will analyze the concepts of tokenization, similarity, and embedding, which are implemented by embedding models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39JsBcy1qnx6"
   },
   "source": [
    "According to OpenAI, as a rule of thumb 1 token corresponds to 4 characters of text for common English text. This means that 100 tokens correspond to 75 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11R9N2xiT8QS"
   },
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnOfOlvXuyto"
   },
   "source": [
    "Embeddings are a way to represent high-dimensional sparse data like words in a more compact, lower-dimensional form while preserving the meaningful similarities between the original data points.. The key ideas are:\n",
    "\n",
    "- **Capturing Similarities:** Similar items, like synonymous words, will have embedding vectors that are close to each other.\n",
    "\n",
    "- **Spatial Representation:** The embedding vectors are positioned in a multi-dimensional space such that the distance between them (e.g. cosine similarity) reflects how related the original data points are\n",
    "\n",
    "<img width=\"1000\" alt=\"Untitled (1)\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/a7e044ab-2c40-47a2-bb05-e86962790ce0\">\n",
    "\n",
    "\n",
    "**Source**: https://openai.com/index/new-embedding-models-and-api-updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwATuxIu1-j7"
   },
   "source": [
    "The most common metric used for similarity search is **cosine similarity**. It finds application in scenarios like semantic search and document classification, because it enables the comparison of vector directions, effectively assessing the overall content of documents. By comparing the vector representations of the query and the documents, cosine similarity can identify the most similar and relevant documents to return in the search results.\n",
    "\n",
    "<img width=\"1000\" alt=\"Screenshot 2024-05-02 123447\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/f5356422-29d6-4a4c-8e11-267ad9115b51\">\n",
    "\n",
    "**Source:** https://www.pinecone.io/learn/vector-similarity/\n",
    "\n",
    "Cosine similarity is a measure of the similarity between two non-zero vectors. It calculates the cosine of the angle between the two vectors, which results in a value between 1 (identical) and -1 (opposite).\n",
    "\n",
    "<img width=\"1000\" alt=\"Screenshot 2024-05-02 122629\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/4215ba02-1fb9-4a72-ad9c-e88740b5a71a\">\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6Oi3sTp9-c7Z"
   },
   "outputs": [],
   "source": [
    "# Define cosine similarity function\n",
    "\n",
    "def cosine_similarity(query_emb, document_emb):\n",
    "\n",
    "    # Calculate the dot product of the query and document embeddings\n",
    "    dot_product = np.dot(query_emb, document_emb)\n",
    "    # Calculate the L2 norms (magnitudes) of the query and document embeddings\n",
    "    query_norm = np.linalg.norm(query_emb)\n",
    "    document_norm = np.linalg.norm(document_emb)\n",
    "    # Calculate the cosine similarity\n",
    "    cosine_sim = dot_product / (query_norm * document_norm)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simple Example of Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlIhiUOkT0kA",
    "outputId": "25c4cea1-3342-4fa0-8457-0b1a08344d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Dimensions: 768\n",
      "Document Dimensions: 768\n",
      "Cosine Similarity: 0.8755725864455451\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "question = \"what is UET Lahore?\"\n",
    "document = \"University of Engineering and Technology (UET) Lahore is a public university located in Lahore, Punjab, Pakistan specializing in STEM subjects. It is one of the oldest and most prestigious institutions of higher learning in Pakistan. UET Lahore was established in 1921 as Mughalpura Technical College and was later renamed as Maclagan Engineering College after Sir Edward Maclagan, the then Governor of the Punjab. In 1923, the college was affiliated with the University of the Punjab for awarding a bachelor's degree in engineering. In 1962, the college was granted university status and was renamed as UET Lahore. The university offers undergraduate, postgraduate, and doctoral programs in various engineering disciplines. UET Lahore is known for its strong emphasis on research and innovation and has produced several notable alumni who have made significant contributions to the field of engineering and technology.\"\n",
    "\n",
    "# Using Google Generative AI EMbeddings Modael\n",
    "\n",
    "query_emb = embeddings.embed_query(question)\n",
    "document_emb = embeddings.embed_query(document)\n",
    "cosine_sim = cosine_similarity(query_emb, document_emb)\n",
    "print(f'Query Dimensions: {len(query_emb)}')\n",
    "print(f'Document Dimensions: {len(document_emb)}')\n",
    "print(\"Cosine Similarity:\", cosine_sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "au8RiAUxjFsh"
   },
   "source": [
    "## Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1FYwcWdoIEC"
   },
   "source": [
    "Unfortunatelly, LLM models have some limitations when it comes to the point of processig text. One of those is the **context window**. The context window represents the maximum amount of text/tokens that a model can process at one time as an input to generate a response. Therefore we need to split our documents into smaller chunks that can fit into the model's context window. A complete list of OpenAI models can be found [here](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4). It spans from 4'096 tokens for the `gpt-3.5-turbo-instruct` to the `gpt-4-turbo` with 128'000 tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr-_ROb1IA5A"
   },
   "source": [
    "Like the data loaders, LangChain offers several text splitters. In the table below you can see the main splitting methods and when to use which one. The `Adds Metadata` does not mean that it will add (or not) the metadata from the previous loader. For example for HTML has a `HTMLHeaderTextSplitter` and it means it will splits text at the element level and adds metadata for each chunk based on header text.\n",
    "\n",
    "In our case we already have the metadata available and we do not need to add them using and splitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLAhUJRQwy7I"
   },
   "source": [
    "<img width=\"863\" alt=\"Screenshot 2024-04-30 132645\" src=\"https://github.com/benitomartin/mlops-car-prices/assets/116911431/7b4dcefb-9320-4085-821f-1b21c81f4d28\">\n",
    "\n",
    "\n",
    "**Source:** https://js.langchain.com/v0.1/docs/modules/data_connection/document_transformers/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKvPq_6t1QRr"
   },
   "source": [
    "The `RecursiveCharacterTextSplitter` is the recommended tool for splitting general text. It segments the text based on a defined chunk size, using a list of characters as separators.\n",
    "\n",
    "According to LangChain, the default separators include [\"\\n\\n\", \"\\n\", \" \", \"\"]. This means it aims to keep paragraphs together first, followed by sentences and words, as they typically exhibit the strongest semantic connections in text.\n",
    "\n",
    "To leverage this feature, we can utilize the `RecursiveCharacterTextSplitter` along with the tiktoken library to ensure that splits do not exceed the maximum token chunk size allowed by the language model. Each split will be recursively divided if its size exceeds the limit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNlR_nsXK4Lr"
   },
   "source": [
    "The final design of our text splitter will be as follows:\n",
    "\n",
    "- Model: `Gimini Pro` with a context window of 16,385 tokens\n",
    "\n",
    "- Chunk Size: number of tokens of one chunk\n",
    "\n",
    "- Chunk Overlap: number of tokens that overlap between two consecutive chunks\n",
    "\n",
    "- Separators: the order of separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pQh6fsFkiINJ"
   },
   "outputs": [],
   "source": [
    "# Splitter\n",
    "# Correct usage of RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=20,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJehbewdYEN9"
   },
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wra5RjZ6K6zH"
   },
   "source": [
    "A Vector Store is a specialized database that is designed to store and manage high-dimensional vector data. Vector databases store data in the form of vector embedding, which can be retrieved by the LLMs and allow them to understand the context and meaning of the data, allowing better responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ETgQax8L-a-"
   },
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEz41Spg_1Ui"
   },
   "source": [
    "Pinecone is a serverless vector store, which shows a very good performance for a fast vector search and retrieval process.\n",
    "\n",
    "The first step to use Pinecone is to create an Index where our embeddings will be stored. There are several parameters to be considered for this:\n",
    "\n",
    "- Index name\n",
    "- Dimension: must be equal to the embedding model dimensions\n",
    "- Metric: must match with the used to tain the embedding model for better results\n",
    "- Serverless specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "U2OgZ6GMBrN9"
   },
   "outputs": [],
   "source": [
    "# Pinecone Initialization\n",
    "index_name = \"langchain-pinecone-malik-uet-lahore\"\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key = PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJA2iaMv9GoF"
   },
   "outputs": [],
   "source": [
    "# Create Index\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"))\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "FGJrKLSkOYJz"
   },
   "outputs": [],
   "source": [
    "# # Delete Index\n",
    "# pc.delete_index('langchain-pinecone-test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBWDX9WeSHII",
    "outputId": "9c436edb-8dde-456b-e663-024a7011c073"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'deletion_protection': 'disabled',\n",
       "              'dimension': 768,\n",
       "              'host': 'langchain-pinecone-malik-gx7zlx1.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'langchain-pinecone-malik',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}},\n",
       "             {'deletion_protection': 'disabled',\n",
       "              'dimension': 768,\n",
       "              'host': 'langchain-pinecone-malik-uet-lahore-gx7zlx1.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'langchain-pinecone-malik-uet-lahore',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List Indexes\n",
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l69uryiAEgJO",
    "outputId": "0cf1ed50-b0db-4a92-88f8-2174033b854e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'first_split': {'vector_count': 116},\n",
       "                'last_split': {'vector_count': 147},\n",
       "                'main': {'vector_count': 1188}},\n",
       " 'total_vector_count': 1451}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe Index this create index \n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_h9IsrSR6pn"
   },
   "source": [
    "### Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7NwkL_x4c1H"
   },
   "source": [
    "Pinecone allows you to split the data into namespaces within an index. This allows to send queries to an specific namespace. You could for example split your data by content, language or any other index suitable for your use case.\n",
    "\n",
    "For this specific example we will first upload 100 records of our data to a namespace and then we will create two splits each with 50 records. In total we will have 3 namspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0_tOz8wmIZeR"
   },
   "outputs": [],
   "source": [
    "# Create Main Namespace\n",
    "splits = text_splitter.split_documents(data)\n",
    "embed = embedding= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "db = PineconeVectorStore.from_documents(documents=splits,\n",
    "                                        embedding=embed,\n",
    "                                        index_name=index_name,\n",
    "                                        namespace=\"main\"\n",
    "                                        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vectorstore of Main index and namespace means we are creating a vectorstore of the documents and their embeddings\n",
    "vectorstore = PineconeVectorStore(index_name=index_name,\n",
    "                                  namespace=\"main\",\n",
    "                                  embedding=embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aji4dicUG98V",
    "outputId": "5dfeb18e-f694-485e-9955-8066b6bbb90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Result Nr. 0-------\n",
      "Page Content: Postgraduate Prospectus 2023 \n",
      " \n",
      " \n",
      "www.uet.edu.pk \n",
      " 31  \n",
      "DEPARTMENT OF COMPUTER SCIENCE \n",
      " \n",
      "Introduction \n",
      " \n",
      "The Department of Computer Science is one of the prominent and oldest centers of computer education in the country. Its history dates back to 1968 when \n",
      " \n",
      "UET Lahore established a Computer Center under the supervision of Department of Mathematics. The center was equipped with a contemporary IBM-1130\n",
      " \n",
      "-------Result Nr. 1-------\n",
      "Page Content: Postgraduate Prospectus 2023 \n",
      " \n",
      " \n",
      "www.uet.edu.pk \n",
      " 31  \n",
      "DEPARTMENT OF COMPUTER SCIENCE \n",
      " \n",
      "Introduction \n",
      " \n",
      "The Department of Computer Science is one of the prominent and oldest centers of computer education in the country. Its history dates back to 1968 when \n",
      " \n",
      "UET Lahore established a Computer Center under the supervision of Department of Mathematics. The center was equipped with a contemporary IBM-1130\n",
      " \n",
      "-------Result Nr. 2-------\n",
      "Page Content: Postgraduate Prospectus 2023 \n",
      " \n",
      " \n",
      "www.uet.edu.pk \n",
      " 31  \n",
      "DEPARTMENT OF COMPUTER SCIENCE \n",
      " \n",
      "Introduction \n",
      " \n",
      "The Department of Computer Science is one of the prominent and oldest centers of computer education in the country. Its history dates back to 1968 when \n",
      " \n",
      "UET Lahore established a Computer Center under the supervision of Department of Mathematics. The center was equipped with a contemporary IBM-1130\n",
      " \n",
      "-------Result Nr. 3-------\n",
      "Page Content: Postgraduate Prospectus 2023 \n",
      " \n",
      " \n",
      "www.uet.edu.pk \n",
      " 36  \n",
      "Postgraduate Faculty & Their Research Interests \n",
      " \n",
      "Teacher Name \n",
      "Research Interest \n",
      "Dr. Muhammad Shoaib \n",
      "Professor and Dean \n",
      "Information Retrieval, Software Metrics, Web Engineering, Management Information Systems. \n",
      "Dr. Ali Hammad Akbar  \n",
      "Professor and Chairman  \n",
      "Computer Networks, Wireless Networks, Internet of Things (IoT), Cyber Security \n",
      "Dr. Muhammad Ali Maud \n",
      "Professor Emeritus  \n",
      "Data Sciences \n",
      "Dr. Muhammad Shahbaz  \n",
      "Professor\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Search for similarity\n",
    "query = \"Who is the Head of Cs Department? of UET Lahore\"\n",
    "similarity = vectorstore.similarity_search(query, k=4)\n",
    "\n",
    "for i in range(len(similarity)):\n",
    "  print(f\"-------Result Nr. {i}-------\")\n",
    "  print(f\"Page Content: {similarity[i].page_content}\")\n",
    "  print(f\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCm3RH93LPne",
    "outputId": "a59b027f-dedf-49ce-f482-6cd111811632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Result Nr. 0-------\n",
      "Page Content: Postgraduate Prospectus 2023 \n",
      " \n",
      " \n",
      "www.uet.edu.pk \n",
      " 31  \n",
      "DEPARTMENT OF COMPUTER SCIENCE \n",
      " \n",
      "Introduction \n",
      " \n",
      "The Department of Computer Science is one of the prominent and oldest centers of computer education in the country. Its history dates back to 1968 when \n",
      " \n",
      "UET Lahore established a Computer Center under the supervision of Department of Mathematics. The center was equipped with a contemporary IBM-1130\n",
      "Score: 0.747562528\n",
      " \n",
      "-------Result Nr. 1-------\n",
      "Page Content: Postgraduate Prospectus 2023 \n",
      " \n",
      " \n",
      "www.uet.edu.pk \n",
      " 31  \n",
      "DEPARTMENT OF COMPUTER SCIENCE \n",
      " \n",
      "Introduction \n",
      " \n",
      "The Department of Computer Science is one of the prominent and oldest centers of computer education in the country. Its history dates back to 1968 when \n",
      " \n",
      "UET Lahore established a Computer Center under the supervision of Department of Mathematics. The center was equipped with a contemporary IBM-1130\n",
      "Score: 0.747562528\n",
      " \n",
      "-------Result Nr. 2-------\n",
      "Page Content: Postgraduate Prospectus 2023 \n",
      " \n",
      " \n",
      "www.uet.edu.pk \n",
      " 31  \n",
      "DEPARTMENT OF COMPUTER SCIENCE \n",
      " \n",
      "Introduction \n",
      " \n",
      "The Department of Computer Science is one of the prominent and oldest centers of computer education in the country. Its history dates back to 1968 when \n",
      " \n",
      "UET Lahore established a Computer Center under the supervision of Department of Mathematics. The center was equipped with a contemporary IBM-1130\n",
      "Score: 0.747562528\n",
      " \n",
      "-------Result Nr. 3-------\n",
      "Page Content: Postgraduate Prospectus 2023 \n",
      " \n",
      " \n",
      "www.uet.edu.pk \n",
      " 36  \n",
      "Postgraduate Faculty & Their Research Interests \n",
      " \n",
      "Teacher Name \n",
      "Research Interest \n",
      "Dr. Muhammad Shoaib \n",
      "Professor and Dean \n",
      "Information Retrieval, Software Metrics, Web Engineering, Management Information Systems. \n",
      "Dr. Ali Hammad Akbar  \n",
      "Professor and Chairman  \n",
      "Computer Networks, Wireless Networks, Internet of Things (IoT), Cyber Security \n",
      "Dr. Muhammad Ali Maud \n",
      "Professor Emeritus  \n",
      "Data Sciences \n",
      "Dr. Muhammad Shahbaz  \n",
      "Professor\n",
      "Score: 0.743688107\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Search for similarity with score\n",
    "\n",
    "query = \"Who is the Head of Cs Department? of UET Lahore\" \n",
    "\n",
    "similarity_with_score = vectorstore.similarity_search_with_score(query, k=4)\n",
    "\n",
    "for i in range(len(similarity_with_score)):\n",
    "  print(f\"-------Result Nr. {i}-------\")\n",
    "  print(f\"Page Content: {similarity[i].page_content}\")\n",
    "  print(f\"Score: {similarity_with_score[i][1]}\")\n",
    "  print(f\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL18xiqISWD6"
   },
   "source": [
    "Now we will create 2 more namespaces each with 50 records. For that we will use the `upsert` function and the `metadata` to add data into our index but in a separate namespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPpmTEfd8h6Y"
   },
   "source": [
    "First we will create the chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHYxmBb-8mLT"
   },
   "source": [
    "The following function will allow to find an specific chunk base on the main speaker. It returns the title and the chunk ID, which can be used to find it in the pinecone cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXHXgo1ABI2v"
   },
   "source": [
    "Now we can see that our index has two namespaces with the below function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZQNDLDIVOvY",
    "outputId": "6a6ba920-0e79-47bd-86a5-f75e941b146d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'main': {'vector_count': 2052}},\n",
       " 'total_vector_count': 2052}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bURbzrM4BQ0a"
   },
   "source": [
    "We can now create the namespace of the second split and check that everything has been properly created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTMbwlt0nzUA",
    "outputId": "79386452-53ad-4d47-9f5d-f073ec3f1652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'main': {'vector_count': 2052}},\n",
       " 'total_vector_count': 2052}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBb0lLb1aikc"
   },
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oykb4AVEGOGr"
   },
   "source": [
    "Now that we have set up our namespaces, we can prepare our RAG pipeline. We will do so, using Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy7TxVjePRKY"
   },
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "y0x1uf06EsXZ"
   },
   "outputs": [],
   "source": [
    "# Create vectorstore\n",
    "# embed = embedding=OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "embed = embedding= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vectorstore = PineconeVectorStore(index_name=index_name,\n",
    "                                  namespace=\"main\",\n",
    "                                  embedding=embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvcx0tsIIOCS"
   },
   "source": [
    "In this retrieval step, you can chose between Open AI or Groq. For Groq, create a `GROQ_API_KEY` which allow you to use some models like llama or mistral for free. We will also add some memory, which allow to keep track of the QA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "gjrtn8aDts1k"
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI  # Import the Google Generative AI model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "# Conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(memory_key='chat_history',k=5,return_messages=True)\n",
    "# Retrieval qa chain\n",
    "qa_db = RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",retriever=vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrjEobt6JDaB"
   },
   "source": [
    "## Augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMy7o9vAKNGr"
   },
   "source": [
    "We are going to use a slightly modified prompt template. First we download the react template, which is a common template using toools and agents and then we will add the instruction of in which tool to look up first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G84UB4TdOaTz"
   },
   "source": [
    "A collection of templates can be found in the [langchain hub](https://smith.langchain.com/hub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nt_x7n23JKit",
    "outputId": "a1cace5f-829b-4e7e-8d68-67d5d7fd107c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CmJ8bCoN7zq"
   },
   "source": [
    "Now we will replace this line:\n",
    "\n",
    "`Action: the action to take, should be one of [{tool_names}]`\n",
    "\n",
    "By this line:\n",
    "\n",
    "`Action: the action to take, should be one of [{tool_names}]. Always look first in Pinecone Document Store`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ybnrDWgibPgy"
   },
   "outputs": [],
   "source": [
    "# Set prompt template\n",
    "\n",
    "template= '''\n",
    "          Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "          {tools}\n",
    "\n",
    "          Use the following format:\n",
    "\n",
    "          Question: the input question you must answer\n",
    "          Thought: you should always think about what to do\n",
    "          Action: the action to take, should be one of [{tool_names}]. Always look first in Pinecone Document Store if not then use the tool\n",
    "          Action Input: the input to the action\n",
    "          Observation: the result of the action\n",
    "          ... (this Thought/Action/Action Input/Observation can repeat 2 times)\n",
    "          Thought: I now know the final answer\n",
    "          Final Answer: the final answer to the original input question\n",
    "\n",
    "          Begin!\n",
    "\n",
    "          Question: {input}\n",
    "          Thought:{agent_scratchpad}\n",
    "          '''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ7UC5I7PXa0"
   },
   "source": [
    "## Generation with Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kr2ckRgNP1Ne"
   },
   "source": [
    "We are going to set up 2 tools for our agent:\n",
    "\n",
    "- Tavily Search API: Tavily search over several sources like Bing or Google and returns the most relevant content. It offers 1000 API calls per month for free.\n",
    "\n",
    "- Vectorstore: Our vector store will be used to look for the information first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "hX7Ur-nQPb6q"
   },
   "outputs": [],
   "source": [
    "# Set up tools and agent\n",
    "import os\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "tavily = TavilySearchResults(max_results=10, tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Pinecone Document Store\",\n",
    "        func = qa_db.run,\n",
    "        description = \"Use it to lookup information from the Pinecone Document Store\"\n",
    "    ),\n",
    "\n",
    "    Tool(\n",
    "        name=\"Tavily\",\n",
    "        func=tavily.run,\n",
    "        description=\"Use this to lookup information from Tavily\",\n",
    "    )\n",
    "     # email sender tool\n",
    "    \n",
    "] \n",
    "agent = create_react_agent(llm,tools,prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "                        tools=tools,\n",
    "                        agent=agent,\n",
    "                        handle_parsing_errors=True,\n",
    "                        verbose=True,\n",
    "                        memory=conversational_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omGlF1tc7II_"
   },
   "source": [
    "Once everything is set up, we can start making queries and check how the agents behave in terms priorization of agent, search quality and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJcPXgySlquf",
    "outputId": "c6f7d140-61bf-499e-a0f7-e0e49bb53190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find information about PROF. DR. HABIB UR REHMAN's role at UET. I can try searching for this information in either the Pinecone Document Store or Tavily. \n",
      "Action: Pinecone Document Store\n",
      "Action Input: \"PROF. DR. HABIB UR REHMAN UET\"\u001b[0m\u001b[36;1m\u001b[1;3mPROF. DR. HABIB UR REHMAN is the Vice Chancellor of the University of Engineering and Technology, Lahore (UET). \n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: I found the answer in the Pinecone Document Store. I don't need to use Tavily.\n",
      "Final Answer: PROF. DR. HABIB UR REHMAN is the Vice Chancellor of the University of Engineering and Technology, Lahore (UET). \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"what is the rola of PROF. DR. HABIB UR REHMAN at UET ?\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7fLQ6u5bPjV",
    "outputId": "10aa2121-1f1a-485e-fcc2-5fcd4412a404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find information about the admission process for UET Lahore, specifically the entrance tests. \n",
      "Action: Tavily\n",
      "Action Input: {\"query\": \"What are the entrance tests for admission to UET Lahore?\"}\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.eduvision.edu.pk/entry-test/uet-lahore-ecat-for-engineering-pattern-deadline-weightage-aggregate-merit', 'content': 'UET Lahore conducts combined entrance tests for admissions to BSc Engineering and BS Technology programs offered by the Government Universities of Punjab.'}, {'url': 'https://www.quora.com/How-can-I-get-admission-to-UET-Lahore-being-a-poor-student', 'content': \"Jul 6, 2020  It's best to check the official website of UET Lahore or contact the admissions ... UET Lahore after scoring good in intermediate and entry test?Missing:  { query : | Show results with:{ query :\"}, {'url': 'https://www.uet.edu.pk/newsannouncement/Event/UET-Lahore-Combined-Entrance-Test-2024-first-For-Admission-In-Engineering-Institutions-Of-The-Punjab-For-B.Sc.-Engineering-B.Sc.-Engineering-Technology-Programs-2024.01.05', 'content': 'The score in this ECAT will be valid for admission in UET in Fall 2024. A common Entrance Test for admission into B.Sc. Engineering and B.Sc. Engineering\\xa0...Missing:  { query : | Show results with:{ query :'}, {'url': 'https://studyobserve.com/uet-lahore-entry-test-schedule-ecat-applying-procedure/', 'content': 'Here every one checks online details about UET Lahore Entry Test Schedule 2024 ECAT Applying Procedure, Centers List, and entry test result.Missing:  { query : | Show results with:{ query :'}, {'url': 'https://starsentrytest.edu.pk/uet-lahore', 'content': 'University of Engineering & Technology (UET) Admissions Test ECAT 2023 for BSc Engineering & BSc Technology will be comducted from Monday through Friday (13-17\\xa0...'}, {'url': 'https://admission.uet.edu.pk/', 'content': 'NFC Institute of Engineering and Fertilizer Research Faisalabad\\nGovernment College of Technology, Railway Road, Lahore\\nGovernment College of Technology, Faisalabad\\nSharif College of Engineering & Technology, Raiwind Road, Lahore\\nQuaid-e-Azam College of Engineering and Technology, Sahiwal\\nSwedish College of Engineering & Technology Rahim Yar Khan\\nSir Syed College of Computer Science, Gulberg, Lahore\\nGovernment Swedish Pakistani College of Technology, Gujrat\\nGrafton College, Islamabad\\nAdmission - 2024\\n|  2024\\nDeadline: February 29, 2024\\nToken Price: 2,500 PKR\\nDeadline: October 06, 2023\\n For merit determination, see page-21 of\\nundergraduate prospectus\\nDeadline: January 30, 2024\\nToken Price: 2,000 PKR\\nHow to Register for ECAT-2024\\nGenerate Challan\\nVisit the Generate Challan page and save the PDF with the serial number and token number.\\n                \\n                 2    \\nAt UET, passing criterion in non-PEC accredited programs (Computer Science, Software Engineering, Architecture, City and Regional Planning, Product Industrial Design and Technology) has been waived off.\\n         \\nAt UET, appearing in ECAT is not required for Energy Systems and Management, Business Administration, Business and Information Technology, Food Science & Technology,\\nEnvironmental Science, Mathematics, Chemistry and Physics.\\n                        \\nPassing ECAT (i.e., at least 132 out of 400) is necessary for PEC-accredited programs only.\\n'}, {'url': 'https://www.topgrade.pk/uet-entry-test-preparation', 'content': 'University of Engineering & Technology (UET) admission test preparation, complete solution offered, save time, effort and money. Modern way of studying,\\xa0...'}, {'url': 'https://www.uet.edu.pk/about-uet/introduction/faqs/', 'content': 'What will the structure of the Admissions Test be? Combined Entry Test for Undergraduate, and GAT for graduate admission. How should I prepare for the\\xa0...Missing:  { query : entrance'}, {'url': 'https://www.youtube.com/watch?v=YsEpH6L96mU', 'content': 'Jun 14, 2024  ... eligibility criteria, entry test, merit, reserved seats, how to apply and deadlines. #admission ...Duration: 13:14Posted: Jun 14, 2024Missing:  { query : entrance'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to find information about the entrance tests for admission to UET Lahore.\n",
      "Action: Tavily\n",
      "Action Input: {\"query\": \"What are the entrance tests for admission to UET Lahore?\"}\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.eduvision.edu.pk/entry-test/uet-lahore-ecat-for-engineering-pattern-deadline-weightage-aggregate-merit', 'content': 'UET Lahore conducts combined entrance tests for admissions to BSc Engineering and BS Technology programs offered by the Government Universities of Punjab.'}, {'url': 'https://www.quora.com/How-can-I-get-admission-to-UET-Lahore-being-a-poor-student', 'content': \"Jul 6, 2020  It's best to check the official website of UET Lahore or contact the admissions ... UET Lahore after scoring good in intermediate and entry test?Missing:  { query : | Show results with:{ query :\"}, {'url': 'https://www.uet.edu.pk/newsannouncement/Event/UET-Lahore-Combined-Entrance-Test-2024-first-For-Admission-In-Engineering-Institutions-Of-The-Punjab-For-B.Sc.-Engineering-B.Sc.-Engineering-Technology-Programs-2024.01.05', 'content': 'The score in this ECAT will be valid for admission in UET in Fall 2024. A common Entrance Test for admission into B.Sc. Engineering and B.Sc. Engineering\\xa0...Missing:  { query : | Show results with:{ query :'}, {'url': 'https://studyobserve.com/uet-lahore-entry-test-schedule-ecat-applying-procedure/', 'content': 'Here every one checks online details about UET Lahore Entry Test Schedule 2024 ECAT Applying Procedure, Centers List, and entry test result.Missing:  { query : | Show results with:{ query :'}, {'url': 'https://starsentrytest.edu.pk/uet-lahore', 'content': 'University of Engineering & Technology (UET) Admissions Test ECAT 2023 for BSc Engineering & BSc Technology will be comducted from Monday through Friday (13-17\\xa0...'}, {'url': 'https://admission.uet.edu.pk/', 'content': 'NFC Institute of Engineering and Fertilizer Research Faisalabad\\nGovernment College of Technology, Railway Road, Lahore\\nGovernment College of Technology, Faisalabad\\nSharif College of Engineering & Technology, Raiwind Road, Lahore\\nQuaid-e-Azam College of Engineering and Technology, Sahiwal\\nSwedish College of Engineering & Technology Rahim Yar Khan\\nSir Syed College of Computer Science, Gulberg, Lahore\\nGovernment Swedish Pakistani College of Technology, Gujrat\\nGrafton College, Islamabad\\nAdmission - 2024\\n|  2024\\nDeadline: February 29, 2024\\nToken Price: 2,500 PKR\\nDeadline: October 06, 2023\\n For merit determination, see page-21 of\\nundergraduate prospectus\\nDeadline: January 30, 2024\\nToken Price: 2,000 PKR\\nHow to Register for ECAT-2024\\nGenerate Challan\\nVisit the Generate Challan page and save the PDF with the serial number and token number.\\n                \\n                 2    \\nAt UET, passing criterion in non-PEC accredited programs (Computer Science, Software Engineering, Architecture, City and Regional Planning, Product Industrial Design and Technology) has been waived off.\\n         \\nAt UET, appearing in ECAT is not required for Energy Systems and Management, Business Administration, Business and Information Technology, Food Science & Technology,\\nEnvironmental Science, Mathematics, Chemistry and Physics.\\n                        \\nPassing ECAT (i.e., at least 132 out of 400) is necessary for PEC-accredited programs only.\\n'}, {'url': 'https://www.topgrade.pk/uet-entry-test-preparation', 'content': 'University of Engineering & Technology (UET) admission test preparation, complete solution offered, save time, effort and money. Modern way of studying,\\xa0...'}, {'url': 'https://www.uet.edu.pk/about-uet/introduction/faqs/', 'content': 'What will the structure of the Admissions Test be? Combined Entry Test for Undergraduate, and GAT for graduate admission. How should I prepare for the\\xa0...Missing:  { query : entrance'}, {'url': 'https://www.youtube.com/watch?v=YsEpH6L96mU', 'content': 'Jun 14, 2024  ... eligibility criteria, entry test, merit, reserved seats, how to apply and deadlines. #admission ...Duration: 13:14Posted: Jun 14, 2024Missing:  { query : entrance'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to find information about the entrance tests for admission to UET Lahore.\n",
      "Action: Tavily\n",
      "Action Input: {\"query\": \"What are the entrance tests for admission to UET Lahore?\"}\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.eduvision.edu.pk/entry-test/uet-lahore-ecat-for-engineering-pattern-deadline-weightage-aggregate-merit', 'content': 'UET Lahore conducts combined entrance tests for admissions to BSc Engineering and BS Technology programs offered by the Government Universities of Punjab.'}, {'url': 'https://www.quora.com/How-can-I-get-admission-to-UET-Lahore-being-a-poor-student', 'content': \"Jul 6, 2020  It's best to check the official website of UET Lahore or contact the admissions ... UET Lahore after scoring good in intermediate and entry test?Missing:  { query : | Show results with:{ query :\"}, {'url': 'https://www.uet.edu.pk/newsannouncement/Event/UET-Lahore-Combined-Entrance-Test-2024-first-For-Admission-In-Engineering-Institutions-Of-The-Punjab-For-B.Sc.-Engineering-B.Sc.-Engineering-Technology-Programs-2024.01.05', 'content': 'The score in this ECAT will be valid for admission in UET in Fall 2024. A common Entrance Test for admission into B.Sc. Engineering and B.Sc. Engineering\\xa0...Missing:  { query : | Show results with:{ query :'}, {'url': 'https://studyobserve.com/uet-lahore-entry-test-schedule-ecat-applying-procedure/', 'content': 'Here every one checks online details about UET Lahore Entry Test Schedule 2024 ECAT Applying Procedure, Centers List, and entry test result.Missing:  { query : | Show results with:{ query :'}, {'url': 'https://www.educoacher.com/2023/12/uet-lahore-entry-test-information-guide.html', 'content': 'Dec 1, 2023  A common Entrance Test for admission into B.Sc. Engineering and B.Sc. Engineering Technology Programs of the Punjab is conducted each year. The\\xa0...'}, {'url': 'https://admission.uet.edu.pk/', 'content': 'NFC Institute of Engineering and Fertilizer Research Faisalabad\\nGovernment College of Technology, Railway Road, Lahore\\nGovernment College of Technology, Faisalabad\\nSharif College of Engineering & Technology, Raiwind Road, Lahore\\nQuaid-e-Azam College of Engineering and Technology, Sahiwal\\nSwedish College of Engineering & Technology Rahim Yar Khan\\nSir Syed College of Computer Science, Gulberg, Lahore\\nGovernment Swedish Pakistani College of Technology, Gujrat\\nGrafton College, Islamabad\\nAdmission - 2024\\n|  2024\\nDeadline: February 29, 2024\\nToken Price: 2,500 PKR\\nDeadline: October 06, 2023\\n For merit determination, see page-21 of\\nundergraduate prospectus\\nDeadline: January 30, 2024\\nToken Price: 2,000 PKR\\nHow to Register for ECAT-2024\\nGenerate Challan\\nVisit the Generate Challan page and save the PDF with the serial number and token number.\\n                \\n                 2    \\nAt UET, passing criterion in non-PEC accredited programs (Computer Science, Software Engineering, Architecture, City and Regional Planning, Product Industrial Design and Technology) has been waived off.\\n         \\nAt UET, appearing in ECAT is not required for Energy Systems and Management, Business Administration, Business and Information Technology, Food Science & Technology,\\nEnvironmental Science, Mathematics, Chemistry and Physics.\\n                        \\nPassing ECAT (i.e., at least 132 out of 400) is necessary for PEC-accredited programs only.\\n'}, {'url': 'https://www.topgrade.pk/uet-entry-test-preparation', 'content': 'University of Engineering & Technology (UET) admission test preparation, complete solution offered, save time, effort and money. Modern way of studying,\\xa0...'}, {'url': 'https://www.uet.edu.pk/about-uet/introduction/faqs/', 'content': 'What will the structure of the Admissions Test be? Combined Entry Test for Undergraduate, and GAT for graduate admission. How should I prepare for the\\xa0...Missing:  { query : entrance'}, {'url': 'https://www.youtube.com/watch?v=YsEpH6L96mU', 'content': 'Jun 14, 2024  ... eligibility criteria, entry test, merit, reserved seats, how to apply and deadlines. #admission ...Duration: 13:14Posted: Jun 14, 2024Missing:  { query : entrance'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The information from Tavily tells me that UET Lahore conducts a combined entrance test for admission to BSc Engineering and BS Technology programs. \n",
      "Final Answer: The combined entrance test, known as ECAT, is required for admission to BSc Engineering and BS Technology programs at UET Lahore. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Which Test is pass to Take Admession in UET Lahore ?',\n",
       " 'chat_history': [HumanMessage(content='what is the rola of PROF. DR. HABIB UR REHMAN at UET ?'),\n",
       "  AIMessage(content='PROF. DR. HABIB UR REHMAN is the Vice Chancellor of the University of Engineering and Technology, Lahore (UET).')],\n",
       " 'output': 'The combined entrance test, known as ECAT, is required for admission to BSc Engineering and BS Technology programs at UET Lahore.'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Which Test is pass to Take Admession in UET Lahore ?\"})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enUSCNdko96E",
    "outputId": "ca3c63cc-9f8a-4817-86ce-135c1b1f3414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find an academic calendar for the 2023-2024 school year.  I can try searching the Pinecone Document Store.\n",
      "Action: Pinecone Document Store\n",
      "Action Input: {\"query\": \"2023-2024 academic calendar\"}\u001b[0m\u001b[36;1m\u001b[1;3mThe Fall Semester starts on Monday, September 04, 2023 and ends on Friday, December 22, 2023. The examination period is from Tuesday, December 26, 2023 to Friday, January 05, 2024.  The semester break is from Monday, January 08, 2024 to Friday, January 12, 2024.\n",
      "\n",
      "The Spring Semester starts on Monday, January 15, 2024 and ends on Friday, May 03, 2024. The examination period is from Tuesday, May 07, 2024 to Friday, May 17, 2024. \n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: The Fall Semester starts on Monday, September 04, 2023 and ends on Friday, December 22, 2023. The examination period is from Tuesday, December 26, 2023 to Friday, January 05, 2024.  The semester break is from Monday, January 08, 2024 to Friday, January 12, 2024.\n",
      "\n",
      "The Spring Semester starts on Monday, January 15, 2024 and ends on Friday, May 03, 2024. The examination period is from Tuesday, May 07, 2024 to Friday, May 17, 2024. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Give me The 2023-2024 academic calander ?',\n",
       " 'chat_history': [HumanMessage(content='what is the rola of PROF. DR. HABIB UR REHMAN at UET ?'),\n",
       "  AIMessage(content='PROF. DR. HABIB UR REHMAN is the Vice Chancellor of the University of Engineering and Technology, Lahore (UET).'),\n",
       "  HumanMessage(content='Which Test is pass to Take Admession in UET Lahore ?'),\n",
       "  AIMessage(content='The combined entrance test, known as ECAT, is required for admission to BSc Engineering and BS Technology programs at UET Lahore.')],\n",
       " 'output': 'The Fall Semester starts on Monday, September 04, 2023 and ends on Friday, December 22, 2023. The examination period is from Tuesday, December 26, 2023 to Friday, January 05, 2024.  The semester break is from Monday, January 08, 2024 to Friday, January 12, 2024.\\n\\nThe Spring Semester starts on Monday, January 15, 2024 and ends on Friday, May 03, 2024. The examination period is from Tuesday, May 07, 2024 to Friday, May 17, 2024.'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Give me The 2023-2024 academic calander ?\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czu_mPH0r4cD",
    "outputId": "682bb84a-e050-43ff-cdf3-e982868814a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find information about ECAT and UET Lahore. I'll start by looking in the Pinecone Document Store.\n",
      "Action: Pinecone Document Store\n",
      "Action Input: \"ECAT UET Lahore\"\u001b[0m\u001b[36;1m\u001b[1;3mI'm sorry, but the provided text does not contain information about ECAT UET Lahore. \n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: Since Pinecone Document Store couldn't find information, I'll try using Tavily.\n",
      "Action: Tavily\n",
      "Action Input: \"What is ECAT of UET Lahore?\"\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.uet.edu.pk/newsannouncement/Event/Entrance-Test-Schedule-and-Admission-Criteria-for-Engineering-Universities-in-Punjab-2024.03.13/?instancedate=1710323905000', 'content': \"The University of Engineering and Technology (UET) Lahore is currently holding 'First ECAT' of the year 2024, for admission in Engineering Programs of Punjab. UET has set up test centers across Punjab for facilitation of candidates. ... UET holds the mandate of conducting ECAT since 1999. Per the instruction of Pakistan Engineering Council ...\"}, {'url': 'https://uet.edu.pk/newsannouncement/Event/UET-Lahore-is-administering-ECAT-2022-for-all-the-public-sector-engineering-universities-of-Punjab-2022.07-00002.18/?instancedate=1658120820000', 'content': 'The University of Engineering and Technology (UET), Lahore is administering the entrance exam, Engineering Colleges Admission Test (ECAT-2022), for all the public-sector engineering universities of Punjab. The computer-based subject test is being executed in UET and seven partner universities concurrently. The test is spread over a week (i.e. ...'}, {'url': 'https://www.eduvision.edu.pk/entry-test/uet-lahore-ecat-for-engineering-pattern-deadline-weightage-aggregate-merit', 'content': 'UET Lahore conducts combined entrance tests for admissions to BSc Engineering and BS Technology programs offered by the Government Universities of Punjab. For 2024 admissions, First UET Combined Entry Test was held from 11-15 March, 2024 and the Second ECAT will be held from May 13 to May 17, 2024 in the assigned Test Centers at the allotted time.You can take any one or both the tests.'}, {'url': 'https://pcgv.org/2024/01/24/online-entrance-test-ecat-2024-first-at-university-of-engineering-and-technology-uet-lahore/', 'content': 'Online Entrance Test (ECAT-2024, First) ... (UET) Lahore will conduct combined entrance test 2024 (First) for admission in Engineering Institutions of the Punjab for B. Sc. Engineering & B.Sc. Engineering Technology Programs from 11th March 2024 to 15th March 2024. As per the notification of Pakistan Engineering Council, the entrance test is ...'}, {'url': 'https://www.studysolutions.pk/official-guidelines-for-uet-lahore-ecat-entry-test-candidates/', 'content': 'As per UET Lahore declaration UET Lahore ECAT entry test 2024 will be comprised of the following portions. 1- English Portion A paragraph will be given in this portion with 10 MCQs related to the paragraph and students will have to choose correct options. 2- Mathematics Portion 30 questions will be asked in this portion related to the syllabus ...'}, {'url': 'https://en.wikipedia.org/wiki/ECAT_Pakistan', 'content': \"Engineering Colleges' Admission Test (ECAT) is a computer-based test conducted in the Punjab, Pakistan each year in March and May for admission in BE/BS/BSc Engineering degree. ECAT is conducted by the University of Engineering and Technology, Lahore.It was started in 1998 on the initiative of then Chief Minister Punjab Mian Muhammad Shahbaz Sharif to counter cheating in the examinations at ...\"}, {'url': 'https://www.uet.edu.pk/newsannouncement/Event/UET-Lahore-Combined-Entrance-Test-2024-first-For-Admission-In-Engineering-Institutions-Of-The-Punjab-For-B.Sc.-Engineering-B.Sc.-Engineering-Technology-Programs-2024.01.05', 'content': 'The score in this ECAT will be valid for admission in UET in Fall 2024. ... (UET) Lahore, Faisalabad Campus, 3.5 KM Khurrian Wala Mukoowana Bypass Road, Faisalabad. Ph #041-2433501; University of Engineering and Technology (UET) Lahore, Narowal Campus, 10 KM Muridke Road, Near Ada Siraj, Narowal Ph # 0542-920351;'}, {'url': 'https://admission.uet.edu.pk/Modules/EntryTestResult/UserRoles/Candidate/LoginPage.aspx/', 'content': 'Government College of Technology, Railway Road, Lahore a) B.Sc. Mechanical Engineering Technology ... Separate Challan is required for applying ECAT and admission in Non-ECAT programs Undergraduate admission process at UET Lahore. Starts on June 11, 2024 Ends on July 09, 2024 at 3:00 pm; The best ECAT result will be used to determine the merit ...'}, {'url': 'https://www.ilmkidunya.com/ecat/', 'content': 'Taught by Hassan graduated from UET Lahore 5 years in honorable Institutions like Unique Group of Institution, Apex college and star Entry test program. ... UET Lahore Announces ECAT Result 2022. 13-Jul-2021. UET ECAT Test 2021 Position Holders. A vibrant community of 492k followers. Join to get daily updates for exams & study activities.'}, {'url': 'https://www.ilmkidunya.com/ecat/ecat-test-scores-merit-lists.aspx', 'content': \"UET ECAT Merit List 2024. ... UET Lahore Announces ECAT Result 2022. 13-Jul-2021. UET ECAT Test 2021 Position Holders. A vibrant community of 492k followers. Join to get daily updates for exams & study activities. Like. Join our 2.38 Million Subscribers on Pakistan's #1 Educational YouTube Channel to keep learning.\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer.\n",
      "Final Answer: ECAT stands for Engineering Colleges Admission Test. UET Lahore conducts ECAT for admission to its engineering programs and for other public sector engineering universities in Punjab. It is a computer-based test that covers topics such as English, Mathematics, and Physics. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Now Tell Me What is ECAT of uet Lahore  ?',\n",
       " 'chat_history': [HumanMessage(content='what is the rola of PROF. DR. HABIB UR REHMAN at UET ?'),\n",
       "  AIMessage(content='PROF. DR. HABIB UR REHMAN is the Vice Chancellor of the University of Engineering and Technology, Lahore (UET).'),\n",
       "  HumanMessage(content='Which Test is pass to Take Admession in UET Lahore ?'),\n",
       "  AIMessage(content='The combined entrance test, known as ECAT, is required for admission to BSc Engineering and BS Technology programs at UET Lahore.'),\n",
       "  HumanMessage(content='Give me The 2023-2024 academic calander ?'),\n",
       "  AIMessage(content='The Fall Semester starts on Monday, September 04, 2023 and ends on Friday, December 22, 2023. The examination period is from Tuesday, December 26, 2023 to Friday, January 05, 2024.  The semester break is from Monday, January 08, 2024 to Friday, January 12, 2024.\\n\\nThe Spring Semester starts on Monday, January 15, 2024 and ends on Friday, May 03, 2024. The examination period is from Tuesday, May 07, 2024 to Friday, May 17, 2024.')],\n",
       " 'output': 'ECAT stands for Engineering Colleges Admission Test. UET Lahore conducts ECAT for admission to its engineering programs and for other public sector engineering universities in Punjab. It is a computer-based test that covers topics such as English, Mathematics, and Physics.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Now Tell Me What is ECAT of uet Lahore  ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVNAQy_PspP0",
    "outputId": "2015b92e-e856-4a30-a55b-b09d07e46837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find information about \"CHANCELLOR'S MESSAGE\". I should check if it's in the Pinecone Document Store first. \n",
      "Action: Pinecone Document Store\n",
      "Action Input: \"CHANCELLOR'S MESSAGE\"\u001b[0m\u001b[36;1m\u001b[1;3mThe University of Engineering and Technology (UET) Lahore holds a place of eminence among the prestigious engineering universities of the world. Being a pioneering institution of engineering and technology in Pakistan, UET has unlocked all its potential in imparting quality education, enabling the students to display scholarly autonomy in learning and research and contribute to sustainable \n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to find information about \"CHANCELLOR'S MESSAGE\". I should check if it's in the Pinecone Document Store first. \n",
      "Action: Pinecone Document Store\n",
      "Action Input: \"CHANCELLOR'S MESSAGE\"\u001b[0m\u001b[36;1m\u001b[1;3mThe University of Engineering and Technology (UET) Lahore holds a place of eminence among the prestigious engineering universities of the world. Being a pioneering institution of engineering and technology in Pakistan, UET has unlocked all its potential in imparting quality education, enabling the students to display scholarly autonomy in learning and research and contribute to sustainable. \n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to find information about \"CHANCELLOR'S MESSAGE\". I should check if it's in the Pinecone Document Store first. \n",
      "Action: Pinecone Document Store\n",
      "Action Input: \"CHANCELLOR'S MESSAGE\"\u001b[0m\u001b[36;1m\u001b[1;3mThe Chancellor's message states that the University of Engineering and Technology (UET) Lahore holds a place of eminence among the prestigious engineering universities of the world.  It highlights UET's role as a pioneering institution in Pakistan, unlocking its potential in imparting quality education and enabling students to display scholarly autonomy in learning and research, contributing to sustainable development. \n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: I found the information about \"CHANCELLOR'S MESSAGE\" in the Pinecone Document Store. \n",
      "Final Answer: The Chancellor's message states that the University of Engineering and Technology (UET) Lahore holds a place of eminence among the prestigious engineering universities of the world. It highlights UET's role as a pioneering institution in Pakistan, unlocking its potential in imparting quality education and enabling students to display scholarly autonomy in learning and research, contributing to sustainable development. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what is CHANCELLOR'S MESSAGE ?\",\n",
       " 'chat_history': [HumanMessage(content='what is the rola of PROF. DR. HABIB UR REHMAN at UET ?'),\n",
       "  AIMessage(content='PROF. DR. HABIB UR REHMAN is the Vice Chancellor of the University of Engineering and Technology, Lahore (UET).'),\n",
       "  HumanMessage(content='Which Test is pass to Take Admession in UET Lahore ?'),\n",
       "  AIMessage(content='The combined entrance test, known as ECAT, is required for admission to BSc Engineering and BS Technology programs at UET Lahore.'),\n",
       "  HumanMessage(content='Give me The 2023-2024 academic calander ?'),\n",
       "  AIMessage(content='The Fall Semester starts on Monday, September 04, 2023 and ends on Friday, December 22, 2023. The examination period is from Tuesday, December 26, 2023 to Friday, January 05, 2024.  The semester break is from Monday, January 08, 2024 to Friday, January 12, 2024.\\n\\nThe Spring Semester starts on Monday, January 15, 2024 and ends on Friday, May 03, 2024. The examination period is from Tuesday, May 07, 2024 to Friday, May 17, 2024.'),\n",
       "  HumanMessage(content='Now Tell Me What is ECAT of uet Lahore  ?'),\n",
       "  AIMessage(content='ECAT stands for Engineering Colleges Admission Test. UET Lahore conducts ECAT for admission to its engineering programs and for other public sector engineering universities in Punjab. It is a computer-based test that covers topics such as English, Mathematics, and Physics.')],\n",
       " 'output': \"The Chancellor's message states that the University of Engineering and Technology (UET) Lahore holds a place of eminence among the prestigious engineering universities of the world. It highlights UET's role as a pioneering institution in Pakistan, unlocking its potential in imparting quality education and enabling students to display scholarly autonomy in learning and research, contributing to sustainable development.\"}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"what is CHANCELLOR'S MESSAGE ?\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lgo9hYXQmChb",
    "outputId": "7f75a347-06d1-45b0-eebe-3df91704ff5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "jMiib6omZZo7"
   },
   "outputs": [],
   "source": [
    "agent_executor.memory.clear()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
