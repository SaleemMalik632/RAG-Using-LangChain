{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Install required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-pinecone"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.7.21 requires urllib3<2, but you have urllib3 2.2.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading langchain_pinecone-0.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.5 (from langchain-pinecone)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-pinecone) (0.2.23)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-pinecone) (1.25.2)\n",
      "Collecting pinecone-client<6.0.0,>=5.0.0 (from langchain-pinecone)\n",
      "  Downloading pinecone_client-5.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (1.9.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.7.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (8.2.3)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2023.7.22)\n",
      "Collecting pinecone-plugin-inference==1.0.2 (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone)\n",
      "  Downloading pinecone_plugin_inference-1.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (4.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.18.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (0.4.4)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.9.5->langchain-pinecone) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (3.2.0)\n",
      "Downloading langchain_pinecone-0.1.3-py3-none-any.whl (10 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/370.8 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/370.8 kB 495.5 kB/s eta 0:00:01\n",
      "   ------ -------------------------------- 61.4/370.8 kB 550.5 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 71.7/370.8 kB 438.9 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 71.7/370.8 kB 438.9 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 122.9/370.8 kB 450.6 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/370.8 kB 449.7 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 153.6/370.8 kB 399.3 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 174.1/370.8 kB 420.1 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 194.6/370.8 kB 421.8 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 204.8/370.8 kB 377.8 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 204.8/370.8 kB 377.8 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 235.5/370.8 kB 369.9 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 235.5/370.8 kB 369.9 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 256.0/370.8 kB 366.3 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 256.0/370.8 kB 366.3 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 276.5/370.8 kB 334.5 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 276.5/370.8 kB 334.5 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 286.7/370.8 kB 310.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 286.7/370.8 kB 310.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 286.7/370.8 kB 310.7 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 307.2/370.8 kB 283.9 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 307.2/370.8 kB 283.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 317.4/370.8 kB 265.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 317.4/370.8 kB 265.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 337.9/370.8 kB 262.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 337.9/370.8 kB 262.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 337.9/370.8 kB 262.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 358.4/370.8 kB 253.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 370.8/370.8 kB 200.8 kB/s eta 0:00:00\n",
      "Downloading pinecone_client-5.0.0-py3-none-any.whl (244 kB)\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/244.8 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/244.8 kB 65.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 30.7/244.8 kB 65.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 30.7/244.8 kB 65.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 30.7/244.8 kB 65.6 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.0/244.8 kB 35.8 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 61.4/244.8 kB 38.6 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 81.9/244.8 kB 41.3 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 92.2/244.8 kB 41.6 kB/s eta 0:00:04\n",
      "   ----------------- --------------------- 112.6/244.8 kB 42.0 kB/s eta 0:00:04\n",
      "   ----------------- --------------------- 112.6/244.8 kB 42.0 kB/s eta 0:00:04\n",
      "   ----------------- --------------------- 112.6/244.8 kB 42.0 kB/s eta 0:00:04\n",
      "   ----------------- --------------------- 112.6/244.8 kB 42.0 kB/s eta 0:00:04\n",
      "   ------------------- ------------------- 122.9/244.8 kB 42.6 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 122.9/244.8 kB 42.6 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 122.9/244.8 kB 42.6 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 122.9/244.8 kB 42.6 kB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 143.4/244.8 kB 47.1 kB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 143.4/244.8 kB 47.1 kB/s eta 0:00:03\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   ------------------------ -------------- 153.6/244.8 kB 48.0 kB/s eta 0:00:02\n",
      "   --------------------------- ----------- 174.1/244.8 kB 47.7 kB/s eta 0:00:02\n",
      "   --------------------------- ----------- 174.1/244.8 kB 47.7 kB/s eta 0:00:02\n",
      "   --------------------------- ----------- 174.1/244.8 kB 47.7 kB/s eta 0:00:02\n",
      "   --------------------------- ----------- 174.1/244.8 kB 47.7 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 184.3/244.8 kB 47.8 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 184.3/244.8 kB 47.8 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 184.3/244.8 kB 47.8 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 184.3/244.8 kB 47.8 kB/s eta 0:00:02\n",
      "   -------------------------------- ------ 204.8/244.8 kB 50.8 kB/s eta 0:00:01\n",
      "   -------------------------------- ------ 204.8/244.8 kB 50.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 225.3/244.8 kB 54.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 235.5/244.8 kB 50.2 kB/s eta 0:00:01\n",
      "   --------------------------------------- 244.8/244.8 kB 51.9 kB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_inference-1.0.2-py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/117.6 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 30.7/117.6 kB 81.9 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.0/117.6 kB 61.4 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 61.4/117.6 kB 48.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 92.2/117.6 kB 56.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 112.6/117.6 kB 61.2 kB/s eta 0:00:01\n",
      "   --------------------------------------- 117.6/117.6 kB 61.9 kB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, aiohttp, pinecone-plugin-inference, pinecone-client, langchain-pinecone\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.6\n",
      "    Uninstalling aiohttp-3.8.6:\n",
      "      Successfully uninstalled aiohttp-3.8.6\n",
      "Successfully installed aiohttp-3.9.5 langchain-pinecone-0.1.3 pinecone-client-5.0.0 pinecone-plugin-inference-1.0.2 pinecone-plugin-interface-0.0.7\n",
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-0.1.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
      "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.3,>=0.2.24 (from langchain-groq)\n",
      "  Downloading langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (2.7.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.10.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.2.24->langchain-groq) (8.2.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.24->langchain-groq) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-groq) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-groq) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-groq) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sonic laptops\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-groq) (2.2.2)\n",
      "Downloading langchain_groq-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.5 kB ? eta -:--:--\n",
      "   --------------- ----------------------- 41.0/103.5 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 103.5/103.5 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.2.24-py3-none-any.whl (377 kB)\n",
      "   ---------------------------------------- 0.0/377.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/377.3 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 143.4/377.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 184.3/377.3 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 204.8/377.3 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 256.0/377.3 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 348.2/377.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 377.3/377.3 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: groq, langchain-core, langchain-groq\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.23\n",
      "    Uninstalling langchain-core-0.2.23:\n",
      "      Successfully uninstalled langchain-core-0.2.23\n",
      "Successfully installed groq-0.9.0 langchain-core-0.2.24 langchain-groq-0.1.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.7.21 requires urllib3<2, but you have urllib3 2.2.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain python-dotenv tiktoken langchain-pinecone openai langchain-openai langchainhub ipykernel pandas langchain-groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd6r8E3wY8hV"
   },
   "source": [
    "# Import Packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "92jiBtwGBSYf"
   },
   "outputs": [],
   "source": [
    "# GLOBAL\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from uuid import uuid4\n",
    "# from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "# LANGCHAIN\n",
    "import langchain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# VECTOR STORE\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# AGENTS\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import AgentExecutor, Tool, AgentType\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyDxC7QLzK-viWHl1-_aBasKex583uFaWbc'\n",
    "os.environ['COHERE_API_KEY'] = 'vRhoY37DN64h1LJ4spzSxSrOMTry8udp2T4satyP'\n",
    "os.environ['PINECONE_API_KEY'] = '080aa9ac-3af8-4cfb-b40d-b88fe5e0ac10'\n",
    "os.environ['TAVILY_API_KEY'] = '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'\n",
    "\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "import google.generativeai as genai\n",
    "GOOGLE_API_KEY= os.getenv('GOOGLE_API_KEY')  \n",
    "genai.configure(api_key=GOOGLE_API_KEY) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yAeKxERZKFS"
   },
   "source": [
    "# Load Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjU_B_teau09"
   },
   "source": [
    "There are several Document Loaders in the LangChain library depending on the type of file to be used. The most common ones include CSV, HTML, JSON, Markdown, File Directory or Microsoft Office formats. The complete list can be found [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/office_file/).\n",
    "\n",
    "However, there is a more extensive [list](https://python.langchain.com/docs/integrations/document_loaders/google_drive/), where you can load directly from Google Cloud, Notion, Youtube or many other services.\n",
    "\n",
    "We will be using a csv file, so we will use the CSVLoader. Below you can find the code to load the file. As arguments we are using:\n",
    "\n",
    "- **file path**\n",
    "- **source column**: indicates the column in the CSV file that contains the primary data of interest, transcript\n",
    "- **metadata columns**: list of column names that contain additional information (metadata) about each entry in the transcript\n",
    "\n",
    "Loading the data in this way will benefit our RAG pipeline. The benefits of metadata are listed further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyEihDI5Qzq2",
    "outputId": "088e416e-dc38-47cf-d668-2dec6b8e33e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2467"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Documents\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=\"./tedx.csv\",\n",
    "    encoding='utf-8',\n",
    "    source_column=\"transcript\",\n",
    "    metadata_columns=[\"main_speaker\", \"name\", \"speaker_occupation\", \"title\", \"url\", \"description\"]\n",
    ")\n",
    "\n",
    "\n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GU89RoE-c7wN"
   },
   "source": [
    "The **CSVLoader** allow us to upload a csv file and there are some arguments that can further enhance the pipeline, mainly metadata.\n",
    "\n",
    "**Benefits of Metadata:**\n",
    "\n",
    "- *Enhanced Retrieval*: Metadata provides additional context about the primary data, which significantly improves the accuracy and relevance of the information retrieved. This is particularly important in RAG, where the goal is to retrieve data that is relevant to a user's query and provide it as context for the LLM. By incorporating metadata, the system can better understand the nuances of the query and retrieve data that is more likely to be relevant to the user's needs. For example, knowing the `main_speaker`, `title`, and `speaker_occupation` can offer insights into the content of the `transcript`.\n",
    "\n",
    "- *Improved Response Generation*: The addition of metadata to the data chunks being processed by the LLM allows for a more nuanced and context-aware retrieval process. This leads to higher quality outcomes in response generation, as the LLM is able to draw upon a richer understanding of the context in which the data is being retrieved.\n",
    "\n",
    "- *Reduced Hallucinations*: By grounding the LLM's output on relevant, external knowledge, RAG attempts to mitigate the risk of responding with incorrect or fabricated information (`hallucinations`). The use of metadata helps to ensure that the responses generated by the LLM are based on accurate and relevant information, rather than simply relying on static training data.\n",
    "\n",
    "- *Domain-Specific Responses*: Metadata can be used to provide domain-specific, relevant responses tailored to an organization's proprietary or domain-specific data. This is particularly important in applications where the LLM needs to provide responses that are specific to a particular domain or industry.\n",
    "\n",
    "- *Efficiency and Cost-Effectiveness*: RAG is a simple and cost-effective approach to customizing LLMs with domain-specific data. By leveraging metadata, organizations can deploy RAG without needing to customize the model, which is especially beneficial when models need to be updated frequently with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4yk-rKc8sEq"
   },
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xijya_O0d2FJ"
   },
   "source": [
    "The **Vector Store Index** is a tool that embeds your documents into vector representations. When you want to search through these embeddings, your query is also converted into a vector embedding. Then, the Vector Store Index performs a mathematical operation to rank all the document embeddings based on how semantically similar they are to your query embedding.\n",
    "\n",
    "The key steps are:\n",
    "- Embedding your documents into vectors\n",
    "- Turning your search query into a vector\n",
    "- Comparing the query vector to all the document vectors\n",
    "- Ranking the document vectors by their similarity to the query vector\n",
    "- Returning the most relevant documents based on this ranking\n",
    "\n",
    "This allows you to search your document collection in a semantic, meaning-based way, rather than just looking for exact keyword matches.\n",
    "\n",
    "To understand the process of vector search, we will analyze the concepts of tokenization, similarity, and embedding, which are implemented by embedding models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvJyFZbPT1CS"
   },
   "source": [
    "## Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqx154RrZWKc"
   },
   "source": [
    "The term **token** refers to the fundamental units of **semantic meaning** that are derived from breaking down a sentence or piece of text. These tokens can then be encoded into vector representations, which are numerical representations that can be processed by large language models (LLMs). Tokens can be words or special characters like punctuation, but also can be `sub-words`.\n",
    "\n",
    "Below is an example of the tiktoken library, which is using the BPE (Byte Pair Encoding) algorithm to convert text into tokens. This library is the one used for models like gpt-3.5 and gpt-4. You can find a good explanation of the BPE algorithm in this link from [Hugging Face](https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt).\n",
    "\n",
    "<img width=\"1000\" alt=\"Screenshot 2024-05-02 112404\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/1bd65cda-519b-4c08-a0d2-0b12e4d2d553\">\n",
    "\n",
    "**Source:** https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxH7C4ZWsOO5"
   },
   "source": [
    "The most common and efficient encoder is the `cl100k_base` with 100k tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tGoOASYT6tC",
    "outputId": "9aceda4f-91f9-43b5-ba97-43e0ad5c251e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words: 8\n",
      "Number of Characters: 36\n",
      "List of Tokens: [4438, 1690, 84296, 87, 13739, 527, 389, 279, 1160, 30]\n",
      "Nr of Tokens: 10\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "# Count the number of tokens in a given string\n",
    "def num_tokens_from_string(question, encoding_name):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = encoding.encode(question)\n",
    "    return encoding, num_tokens\n",
    "\n",
    "\n",
    "question = \"How many TEDx talks are on the list?\"\n",
    "encoding, num_tokens = num_tokens_from_string(question, \"cl100k_base\")\n",
    "print(f'Number of Words: {len(question.split())}')\n",
    "print(f'Number of Characters: {len(question)}')\n",
    "print(f'List of Tokens: {num_tokens}')\n",
    "print(f'Nr of Tokens: {len(num_tokens)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5Hzu2WKnpGZe",
    "outputId": "057de8f6-0cf1-4a83-f763-879de73c4d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many TEDx talks are on the list?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decoding tokenizer\n",
    "encoding.decode([4438, 1690, 84296, 87, 13739, 527, 389, 279, 1160, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_CB2ZBQV_NJ"
   },
   "source": [
    "<img width=\"1000\" alt=\"Screenshot 2024-05-02 100606\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/830d95fa-776c-46f6-adb8-429836f4a887\">\n",
    "\n",
    "**Source:** https://tiktokenizer.vercel.app/?model=cl100k_base\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39JsBcy1qnx6"
   },
   "source": [
    "According to OpenAI, as a rule of thumb 1 token corresponds to 4 characters of text for common English text. This means that 100 tokens correspond to 75 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11R9N2xiT8QS"
   },
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnOfOlvXuyto"
   },
   "source": [
    "Embeddings are a way to represent high-dimensional sparse data like words in a more compact, lower-dimensional form while preserving the meaningful similarities between the original data points.. The key ideas are:\n",
    "\n",
    "- **Capturing Similarities:** Similar items, like synonymous words, will have embedding vectors that are close to each other.\n",
    "\n",
    "- **Spatial Representation:** The embedding vectors are positioned in a multi-dimensional space such that the distance between them (e.g. cosine similarity) reflects how related the original data points are\n",
    "\n",
    "<img width=\"1000\" alt=\"Untitled (1)\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/a7e044ab-2c40-47a2-bb05-e86962790ce0\">\n",
    "\n",
    "\n",
    "**Source**: https://openai.com/index/new-embedding-models-and-api-updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwATuxIu1-j7"
   },
   "source": [
    "The most common metric used for similarity search is **cosine similarity**. It finds application in scenarios like semantic search and document classification, because it enables the comparison of vector directions, effectively assessing the overall content of documents. By comparing the vector representations of the query and the documents, cosine similarity can identify the most similar and relevant documents to return in the search results.\n",
    "\n",
    "<img width=\"1000\" alt=\"Screenshot 2024-05-02 123447\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/f5356422-29d6-4a4c-8e11-267ad9115b51\">\n",
    "\n",
    "**Source:** https://www.pinecone.io/learn/vector-similarity/\n",
    "\n",
    "Cosine similarity is a measure of the similarity between two non-zero vectors. It calculates the cosine of the angle between the two vectors, which results in a value between 1 (identical) and -1 (opposite).\n",
    "\n",
    "<img width=\"1000\" alt=\"Screenshot 2024-05-02 122629\" src=\"https://github.com/benitomartin/nlp-news-classification/assets/116911431/4215ba02-1fb9-4a72-ad9c-e88740b5a71a\">\n",
    "\n",
    "**Source:** https://medium.com/kx-systems/how-vector-databases-search-by-similarity-a-comprehensive-primer-c4b80d13ce63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6Oi3sTp9-c7Z"
   },
   "outputs": [],
   "source": [
    "# Define cosine similarity function\n",
    "\n",
    "def cosine_similarity(query_emb, document_emb):\n",
    "\n",
    "    # Calculate the dot product of the query and document embeddings\n",
    "    dot_product = np.dot(query_emb, document_emb)\n",
    "\n",
    "    # Calculate the L2 norms (magnitudes) of the query and document embeddings\n",
    "    query_norm = np.linalg.norm(query_emb)\n",
    "    document_norm = np.linalg.norm(document_emb)\n",
    "\n",
    "    # Calculate the cosine similarity\n",
    "    cosine_sim = dot_product / (query_norm * document_norm)\n",
    "\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlIhiUOkT0kA",
    "outputId": "25c4cea1-3342-4fa0-8457-0b1a08344d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Dimensions: 768\n",
      "Document Dimensions: 768\n",
      "Cosine Similarity: 0.6499170772110668\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "question = \"What is the topic of the TEDx talk from Al Gore?\"\n",
    "document = \"Averting the climate crisis\"\n",
    "\n",
    "# Using Google Generative AI EMbeddings Modael\n",
    "\n",
    "query_emb = embeddings.embed_query(question)\n",
    "document_emb = embeddings.embed_query(document)\n",
    "cosine_sim = cosine_similarity(query_emb, document_emb)\n",
    "print(f'Query Dimensions: {len(query_emb)}')\n",
    "print(f'Document Dimensions: {len(document_emb)}')\n",
    "print(\"Cosine Similarity:\", cosine_sim)\n",
    "\n",
    "\n",
    "\n",
    "# Using OpenAI GPT-3 model\n",
    "# embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "# query_emb = embedding.embed_query(question)\n",
    "# document_emb = embedding.embed_query(document)\n",
    "# cosine_sim = cosine_similarity(query_emb, document_emb)\n",
    "# print(f'Query Dimensions: {len(query_emb)}')\n",
    "# print(f'Document Dimensions: {len(document_emb)}')\n",
    "# print(\"Cosine Similarity:\", cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "au8RiAUxjFsh"
   },
   "source": [
    "## Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1FYwcWdoIEC"
   },
   "source": [
    "Unfortunatelly, LLM models have some limitations when it comes to the point of processig text. One of those is the **context window**. The context window represents the maximum amount of text/tokens that a model can process at one time as an input to generate a response. Therefore we need to split our documents into smaller chunks that can fit into the model's context window. A complete list of OpenAI models can be found [here](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4). It spans from 4'096 tokens for the `gpt-3.5-turbo-instruct` to the `gpt-4-turbo` with 128'000 tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr-_ROb1IA5A"
   },
   "source": [
    "Like the data loaders, LangChain offers several text splitters. In the table below you can see the main splitting methods and when to use which one. The `Adds Metadata` does not mean that it will add (or not) the metadata from the previous loader. For example for HTML has a `HTMLHeaderTextSplitter` and it means it will splits text at the element level and adds metadata for each chunk based on header text.\n",
    "\n",
    "In our case we already have the metadata available and we do not need to add them using and splitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLAhUJRQwy7I"
   },
   "source": [
    "<img width=\"863\" alt=\"Screenshot 2024-04-30 132645\" src=\"https://github.com/benitomartin/mlops-car-prices/assets/116911431/7b4dcefb-9320-4085-821f-1b21c81f4d28\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKvPq_6t1QRr"
   },
   "source": [
    "The `RecursiveCharacterTextSplitter` is the recommended tool for splitting general text. It segments the text based on a defined chunk size, using a list of characters as separators.\n",
    "\n",
    "According to LangChain, the default separators include [\"\\n\\n\", \"\\n\", \" \", \"\"]. This means it aims to keep paragraphs together first, followed by sentences and words, as they typically exhibit the strongest semantic connections in text.\n",
    "\n",
    "To leverage this feature, we can utilize the `RecursiveCharacterTextSplitter` along with the tiktoken library to ensure that splits do not exceed the maximum token chunk size allowed by the language model. Each split will be recursively divided if its size exceeds the limit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNlR_nsXK4Lr"
   },
   "source": [
    "The final design of our text splitter will be as follows:\n",
    "\n",
    "- Model: `gpt-3.5-turbo-0125` with a context window of 16,385 tokens\n",
    "\n",
    "- Chunk Size: number of tokens of one chunk\n",
    "\n",
    "- Chunk Overlap: number of tokens that overlap between two consecutive chunks\n",
    "\n",
    "- Separators: the order of separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pQh6fsFkiINJ"
   },
   "outputs": [],
   "source": [
    "# Splitter\n",
    "# Correct usage of RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=20,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJehbewdYEN9"
   },
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wra5RjZ6K6zH"
   },
   "source": [
    "A Vector Store is a specialized database that is designed to store and manage high-dimensional vector data. Vector databases store data in the form of vector embedding, which can be retrieved by the LLMs and allow them to understand the context and meaning of the data, allowing better responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ETgQax8L-a-"
   },
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEz41Spg_1Ui"
   },
   "source": [
    "Pinecone is a serverless vector store, which shows a very good performance for a fast vector search and retrieval process.\n",
    "\n",
    "The first step to use Pinecone is to create an Index where our embeddings will be stored. There are several parameters to be considered for this:\n",
    "\n",
    "- Index name\n",
    "- Dimension: must be equal to the embedding model dimensions\n",
    "- Metric: must match with the used to tain the embedding model for better results\n",
    "- Serverless specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U2OgZ6GMBrN9"
   },
   "outputs": [],
   "source": [
    "# Pinecone Initialization\n",
    "index_name = \"langchain-pinecone-malik\"\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key = PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJA2iaMv9GoF"
   },
   "outputs": [],
   "source": [
    "# Create Index\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"))\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "FGJrKLSkOYJz"
   },
   "outputs": [],
   "source": [
    "# # Delete Index\n",
    "# pc.delete_index('langchain-pinecone-test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBWDX9WeSHII",
    "outputId": "9c436edb-8dde-456b-e663-024a7011c073"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'deletion_protection': 'disabled',\n",
       "              'dimension': 768,\n",
       "              'host': 'langchain-pinecone-malik-gx7zlx1.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'langchain-pinecone-malik',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List Indexes\n",
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l69uryiAEgJO",
    "outputId": "0cf1ed50-b0db-4a92-88f8-2174033b854e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'first_split': {'vector_count': 1709},\n",
       "                'last_split': {'vector_count': 1416},\n",
       "                'main': {'vector_count': 6250}},\n",
       " 'total_vector_count': 9375}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe Index\n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_h9IsrSR6pn"
   },
   "source": [
    "### Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7NwkL_x4c1H"
   },
   "source": [
    "Pinecone allows you to split the data into namespaces within an index. This allows to send queries to an specific namespace. You could for example split your data by content, language or any other index suitable for your use case.\n",
    "\n",
    "For this specific example we will first upload 100 records of our data to a namespace and then we will create two splits each with 50 records. In total we will have 3 namspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0_tOz8wmIZeR"
   },
   "outputs": [],
   "source": [
    "# Create Main Namespace\n",
    "splits = text_splitter.split_documents(data[:100])\n",
    "embed = embedding= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "db = PineconeVectorStore.from_documents(documents=splits,\n",
    "                                        embedding=embed,\n",
    "                                        index_name=index_name,\n",
    "                                        namespace=\"main\"\n",
    "                                        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vectorstore of Main index\n",
    "vectorstore = PineconeVectorStore(index_name=index_name,\n",
    "                                  namespace=\"main\",\n",
    "                                  embedding=embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aji4dicUG98V",
    "outputId": "5dfeb18e-f694-485e-9955-8066b6bbb90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Result Nr. 0-------\n",
      "Main Speaker: Al Gore\n",
      " \n",
      "-------Result Nr. 1-------\n",
      "Main Speaker: Al Gore\n",
      " \n",
      "-------Result Nr. 2-------\n",
      "Main Speaker: Al Gore\n",
      " \n",
      "-------Result Nr. 3-------\n",
      "Main Speaker: Al Gore\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Search for similarity\n",
    "query = \"Who is Al Gore\"\n",
    "similarity = vectorstore.similarity_search(query, k=4)\n",
    "\n",
    "for i in range(len(similarity)):\n",
    "  print(f\"-------Result Nr. {i}-------\")\n",
    "  print(f\"Main Speaker: {similarity[i].metadata['main_speaker']}\")\n",
    "  print(f\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCm3RH93LPne",
    "outputId": "a59b027f-dedf-49ce-f482-6cd111811632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Result Nr. 0-------\n",
      "Title: Averting the climate crisis\n",
      "Main Speaker: Al Gore\n",
      "Score: 0.723353803\n",
      "Description: With the same humor and humanity he exuded in \"An Inconvenient Truth,\" Al Gore spells out 15 ways that individuals can address climate change immediately, from buying a hybrid to inventing a new, hotter brand name for global warming.\n",
      " \n",
      "-------Result Nr. 1-------\n",
      "Title: Averting the climate crisis\n",
      "Main Speaker: Al Gore\n",
      "Score: 0.723353803\n",
      "Description: With the same humor and humanity he exuded in \"An Inconvenient Truth,\" Al Gore spells out 15 ways that individuals can address climate change immediately, from buying a hybrid to inventing a new, hotter brand name for global warming.\n",
      " \n",
      "-------Result Nr. 2-------\n",
      "Title: Averting the climate crisis\n",
      "Main Speaker: Al Gore\n",
      "Score: 0.723353803\n",
      "Description: With the same humor and humanity he exuded in \"An Inconvenient Truth,\" Al Gore spells out 15 ways that individuals can address climate change immediately, from buying a hybrid to inventing a new, hotter brand name for global warming.\n",
      " \n",
      "-------Result Nr. 3-------\n",
      "Title: My wish: Rebuilding Rwanda\n",
      "Main Speaker: Bill Clinton\n",
      "Score: 0.719050825\n",
      "Description: Accepting the 2007 TED Prize, Bill Clinton asks for help in bringing health care to Rwanda -- and the rest of the world.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Search for similarity with score\n",
    "\n",
    "query = \"Who is Al Gore\"\n",
    "\n",
    "similarity_with_score = vectorstore.similarity_search_with_score(query, k=4)\n",
    "\n",
    "for i in range(len(similarity_with_score)):\n",
    "  print(f\"-------Result Nr. {i}-------\")\n",
    "  print(f\"Title: {similarity_with_score[i][0].metadata['title']}\")\n",
    "  print(f\"Main Speaker: {similarity_with_score[i][0].metadata['main_speaker']}\")\n",
    "  print(f\"Score: {similarity_with_score[i][1]}\")\n",
    "  print(f\"Description: {similarity_with_score[i][0].metadata['description']}\")\n",
    "  print(f\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL18xiqISWD6"
   },
   "source": [
    "Now we will create 2 more namespaces each with 50 records. For that we will use the `upsert` function and the `metadata` to add data into our index but in a separate namespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPpmTEfd8h6Y"
   },
   "source": [
    "First we will create the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LL1asFW9orPU"
   },
   "outputs": [],
   "source": [
    "# Create Chunked Metadata\n",
    "def chunked_metadata_embeddings(documents, embed):\n",
    "\n",
    "    chunked_metadata = []\n",
    "    chunked_text = text_splitter.split_documents(documents)\n",
    "    for index, text in enumerate(tqdm(chunked_text)):\n",
    "        payload = {\n",
    "              \"metadata\": {\n",
    "                  \"source\": text.metadata['source'],\n",
    "                  \"row\": text.metadata['row'],\n",
    "                  \"chunk_num\": index,\n",
    "                  \"main_speaker\": text.metadata['main_speaker'],\n",
    "                  \"name\": text.metadata['name'],\n",
    "                  \"speaker_occupation\": text.metadata['speaker_occupation'],\n",
    "                  \"title\": text.metadata['title'],\n",
    "                  \"url\": text.metadata['url'],\n",
    "                  \"description\": text.metadata['description'],\n",
    "              },\n",
    "              \"id\": str(uuid4()),\n",
    "              \"values\": embed.embed_documents([text.page_content])[0]  # Assuming `embed` is defined elsewhere\n",
    "          }\n",
    "        chunked_metadata.append(payload)\n",
    "    return chunked_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEc6jx2Fr3J-",
    "outputId": "50112bc8-4a56-4a6a-a1eb-d089bb50b3d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c4a32992654d59879555b41d2e9496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create first split\n",
    "split_one = chunked_metadata_embeddings(data[:20], embed) \n",
    "len(split_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4rxf1c2bK3n",
    "outputId": "c7a3fee1-cc9a-48d0-a4e0-41913daf1cd2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be82112e0d14b228e68a2d4bde6dbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create second split\n",
    "split_two = chunked_metadata_embeddings(data[20:50], embed)\n",
    "len(split_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lcjrk4IyaWQj"
   },
   "outputs": [],
   "source": [
    "# Upsert the document\n",
    "\n",
    "def batch_upsert(split,index ,namespace,batch_size):\n",
    "    print(f\"Split Length: {len(split)}\")\n",
    "    for i in range(0, len(split), batch_size):\n",
    "      batch = split[i:i + batch_size] \n",
    "      index.upsert(vectors=batch,\n",
    "                   namespace=namespace) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFOJXxR2TxZA",
    "outputId": "08ad134f-9a6e-4bf4-820a-43b953fe9437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Length: 675\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(split_one, index, \"first_split\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHYxmBb-8mLT"
   },
   "source": [
    "The following function will allow to find an specific chunk base on the main speaker. It returns the title and the chunk ID, which can be used to find it in the pinecone cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49OxGuRdJvLC",
    "outputId": "78344df1-719c-4ff2-8854-a2b34fd286b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Nr: 36\n",
      "Chunk ID: f8fff39d-5443-4b95-b227-38a3c20194fd\n",
      "Chunk Title: Averting the climate crisis\n"
     ]
    }
   ],
   "source": [
    "# Function to find item with main_speaker\n",
    "\n",
    "def find_item_with_row(metadata_list, main_speaker):\n",
    "    for item in metadata_list:\n",
    "        if item['metadata']['main_speaker'] == main_speaker:\n",
    "            return item\n",
    "\n",
    "# Call the function to find item with main_speaker = Al Gore\n",
    "result_item = find_item_with_row(split_one, \"Al Gore\")\n",
    "\n",
    "# Print the result\n",
    "print(f'Chunk Nr: {result_item[\"metadata\"][\"chunk_num\"]}')\n",
    "print(f'Chunk ID: {result_item[\"id\"]}')\n",
    "print(f'Chunk Title: {result_item[\"metadata\"][\"title\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjbCOjQoAVPZ"
   },
   "source": [
    "\n",
    "<img width=\"695\" alt=\"Screenshot 2024-05-10 140026\" src=\"https://github.com/benitomartin/Agentic-RAG-Langchain-Pinecone/assets/116911431/6a311659-d8da-4679-a705-9c78fd07aece\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "vsKGF7UyBHEH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index.delete(namespace=\"last_split\", delete_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXHXgo1ABI2v"
   },
   "source": [
    "Now we can see that our index has two namespaces with the below function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZQNDLDIVOvY",
    "outputId": "6a6ba920-0e79-47bd-86a5-f75e941b146d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'first_split': {'vector_count': 2444},\n",
       "                'last_split': {'vector_count': 1416},\n",
       "                'main': {'vector_count': 9375}},\n",
       " 'total_vector_count': 13235}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bURbzrM4BQ0a"
   },
   "source": [
    "We can now create the namespace of the second split and check that everything has been properly created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXJD50u-W8h_",
    "outputId": "9469c337-3005-49dd-b7b3-f6aed81de841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Length: 1034\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(split_two, index, \"last_split\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTMbwlt0nzUA",
    "outputId": "79386452-53ad-4d47-9f5d-f073ec3f1652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'first_split': {'vector_count': 2384},\n",
       "                'last_split': {'vector_count': 2450},\n",
       "                'main': {'vector_count': 9375}},\n",
       " 'total_vector_count': 14209}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN_LDV2iB_MV"
   },
   "source": [
    "<img width=\"691\" alt=\"Screenshot 2024-05-10 135858\" src=\"https://github.com/benitomartin/Agentic-RAG-Langchain-Pinecone/assets/116911431/b6f12941-67c7-4420-afbe-b953f753a4b0\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDmu-cbWDsl6"
   },
   "source": [
    "Now we will test our namespaces by creating two users, each of one will send the query to a different namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dVNt8LFH9o0Q"
   },
   "outputs": [],
   "source": [
    "# Define Users\n",
    "\n",
    "query_one = \"Who is Al Gore?\"\n",
    "query_two = \"Who is Rick Warren?\"\n",
    "# Users dictionary\n",
    "users = [{\n",
    "            'name': 'John',\n",
    "            'namespace': 'first_split',\n",
    "            'query': query_one\n",
    "\n",
    "            },\n",
    "           {\n",
    "             \"name\": \"Jane\",\n",
    "             \"namespace\": 'last_split',\n",
    "             \"query\": query_two\n",
    "           }]\n",
    "\n",
    "def vectorize_query(embed, query):\n",
    "    return embed.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tkBgMDGW9o2n"
   },
   "outputs": [],
   "source": [
    "# Create our vectors for each of our queries:\n",
    "\n",
    "query_vector_one = vectorize_query(embed, query_one)\n",
    "query_vector_two = vectorize_query(embed, query_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FK6c_xfz_aet",
    "outputId": "1f6efa7b-3b76-413f-f865-d11251836feb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_vector_one), len(query_vector_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "GmDjNDOD9o4p"
   },
   "outputs": [],
   "source": [
    "# Define a list of new key-value pairs\n",
    "\n",
    "new_key_value_pairs = [\n",
    "    {'vector_query': query_vector_one},\n",
    "    {'vector_query': query_vector_two},\n",
    "\n",
    "]\n",
    "\n",
    "# Loop through the list of users and the list of new key-value pairs \n",
    "for user, new_pair in zip(users, new_key_value_pairs):\n",
    "    user.update(new_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KmY_hvCEEl1p",
    "outputId": "ab048dbe-fe3b-49f4-e860-562c37df66e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('John', 'Jane')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[0][\"name\"], users[1][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfoA7_ma_4jg",
    "outputId": "92d70abe-6119-4ef9-edd8-ea2d4bfc221c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'namespace', 'query', 'vector_query'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ft-xXh1a_ZX1",
    "outputId": "5039c9b5-1fd5-4166-c30d-e2482efc90eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John\n",
      "Namespace: first_split\n",
      "Query: Who is Al Gore?\n",
      "Vector Query: [0.027478035539388657, -0.04128848761320114, -0.006325118243694305]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name: {users[0]['name']}\")\n",
    "print(f\"Namespace: {users[0]['namespace']}\")\n",
    "print(f\"Query: {users[0]['query']}\")\n",
    "print(f\"Vector Query: {users[0]['vector_query'][:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w457e4_ZFUYw"
   },
   "source": [
    "If we send the query to the namespace, we will get the `top_k` vectors related to that query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAGLPEJFtsy-",
    "outputId": "9f74fa0c-28d6-449e-cb39-76f05b01eb34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '59e44463-59b8-4f60-b155-59ec01e4d2c5',\n",
       "              'metadata': {'chunk_num': 44.0,\n",
       "                           'description': 'With the same humor and humanity he '\n",
       "                                          'exuded in \"An Inconvenient Truth,\" '\n",
       "                                          'Al Gore spells out 15 ways that '\n",
       "                                          'individuals can address climate '\n",
       "                                          'change immediately, from buying a '\n",
       "                                          'hybrid to inventing a new, hotter '\n",
       "                                          'brand name for global warming.',\n",
       "                           'main_speaker': 'Al Gore',\n",
       "                           'name': 'Al Gore: Averting the climate crisis',\n",
       "                           'row': 1.0,\n",
       "                           'source': \"Thank you so much, Chris. And it's truly \"\n",
       "                                     'a great honor to have the opportunity to '\n",
       "                                     \"come to this stage twice; I'm extremely \"\n",
       "                                     'grateful. I have been blown away by this '\n",
       "                                     'conference, and I want to thank all of '\n",
       "                                     'you for the many nice comments about '\n",
       "                                     'what I had to say the other night. And I '\n",
       "                                     'say that sincerely, partly because (Mock '\n",
       "                                     'sob) I need that.(Laughter)Put '\n",
       "                                     'yourselves in my position.(Laughter)I '\n",
       "                                     'flew on Air Force Two for eight '\n",
       "                                     'years.(Laughter)Now I have to take off '\n",
       "                                     'my shoes or boots to get on an '\n",
       "                                     \"airplane!(Laughter)(Applause)I'll tell \"\n",
       "                                     'you one quick story to illustrate what '\n",
       "                                     \"that's been like for me.(Laughter)It's a \"\n",
       "                                     'true story  every bit of this is '\n",
       "                                     'true.Soon after Tipper and I left the  '\n",
       "                                     '(Mock sob) White House (Laughter)we '\n",
       "                                     'were driving from our home in Nashville '\n",
       "                                     'to a little farm we have 50 miles east '\n",
       "                                     'of Nashville. Driving '\n",
       "                                     'ourselves.(Laughter)I know it sounds '\n",
       "                                     'like a little thing to you, but '\n",
       "                                     '(Laughter)I looked in the rear-view '\n",
       "                                     'mirror and all of a sudden it just hit '\n",
       "                                     'me. There was no motorcade back '\n",
       "                                     \"there.(Laughter)You've heard of phantom \"\n",
       "                                     'limb pain?(Laughter)This was a rented '\n",
       "                                     'Ford Taurus.(Laughter)It was dinnertime, '\n",
       "                                     'and we started looking for a place to '\n",
       "                                     'eat. We were on I-40. We got to Exit '\n",
       "                                     '238, Lebanon, Tennessee. We got off the '\n",
       "                                     \"exit, we found a Shoney's restaurant. \"\n",
       "                                     'Low-cost family restaurant chain, for '\n",
       "                                     \"those of you who don't know it. We went \"\n",
       "                                     'in and sat down at the booth, and the '\n",
       "                                     'waitress came over, made a big commotion '\n",
       "                                     'over Tipper.(Laughter)She took our '\n",
       "                                     'order, and then went to the couple in '\n",
       "                                     'the booth next to us, and she lowered '\n",
       "                                     'her voice so much, I had to really '\n",
       "                                     'strain to hear what she was saying. And '\n",
       "                                     'she said \"Yes, that\\'s former Vice '\n",
       "                                     'President Al Gore and his wife, Tipper.\" '\n",
       "                                     'And the man said, \"He\\'s come down a '\n",
       "                                     \"long way, hasn't \"\n",
       "                                     'he?\"(Laughter)(Applause)There\\'s been '\n",
       "                                     'kind of a series of '\n",
       "                                     'epiphanies.(Laughter)The very next day, '\n",
       "                                     'continuing the totally true story, I got '\n",
       "                                     'on a G-V to fly to Africa to make a '\n",
       "                                     'speech in Nigeria, in the city of Lagos, '\n",
       "                                     'on the topic of energy. And I began the '\n",
       "                                     'speech by telling them the story of what '\n",
       "                                     'had just happened the day before in '\n",
       "                                     'Nashville. And I told it pretty much the '\n",
       "                                     \"same way I've just shared it with you: \"\n",
       "                                     'Tipper and I were driving ourselves, '\n",
       "                                     \"Shoney's, low-cost family restaurant \"\n",
       "                                     'chain, what the man said  they laughed. '\n",
       "                                     'I gave my speech, then went back out to '\n",
       "                                     'the airport to fly back home. I fell '\n",
       "                                     'asleep on the plane until, during the '\n",
       "                                     'middle of the night, we landed on the '\n",
       "                                     'Azores Islands for refueling. I woke up, '\n",
       "                                     'they opened the door, I went out to get '\n",
       "                                     'some fresh air, and I looked, and there '\n",
       "                                     'was a man running across the runway. And '\n",
       "                                     'he was waving a piece of paper, and he '\n",
       "                                     'was yelling, \"Call Washington! Call '\n",
       "                                     'Washington!\" And I thought to myself, in '\n",
       "                                     'the middle of the night, in the middle '\n",
       "                                     'of the Atlantic, what in the world could '\n",
       "                                     'be wrong in Washington? Then I '\n",
       "                                     'remembered it could be a bunch of '\n",
       "                                     'things.(Laughter)But what it turned out '\n",
       "                                     'to be, was that my staff was extremely '\n",
       "                                     'upset because one of the wire services '\n",
       "                                     'in Nigeria had already written a story '\n",
       "                                     'about my speech, and it had already been '\n",
       "                                     'printed in cities all across the United '\n",
       "                                     'States of America. It was printed in '\n",
       "                                     'Monterey, I checked.(Laughter)And the '\n",
       "                                     'story began, \"Former Vice President Al '\n",
       "                                     'Gore announced in Nigeria yesterday,\" '\n",
       "                                     \"quote: 'My wife Tipper and I have opened \"\n",
       "                                     'a low-cost family restaurant\\'\" '\n",
       "                                     '(Laughter)\"\\'named Shoney\\'s, and we '\n",
       "                                     'are running it '\n",
       "                                     'ourselves.\\'\"(Laughter)Before I could '\n",
       "                                     'get back to U.S. soil, David Letterman '\n",
       "                                     'and Jay Leno had already started in on  '\n",
       "                                     \"one of them had me in a big white chef's \"\n",
       "                                     'hat, Tipper was saying, \"One more burger '\n",
       "                                     'with fries!\"(Laughter)Three days later, '\n",
       "                                     'I got a nice, long, handwritten letter '\n",
       "                                     'from my friend and partner and colleague '\n",
       "                                     'Bill Clinton, saying, \"Congratulations '\n",
       "                                     'on the new restaurant, Al!\"(Laughter)We '\n",
       "                                     \"like to celebrate each other's successes \"\n",
       "                                     'in life.(Laughter)I was going to talk '\n",
       "                                     'about information ecology. But I was '\n",
       "                                     'thinking that, since I plan to make a '\n",
       "                                     'lifelong habit of coming back to TED, '\n",
       "                                     'that maybe I could talk about that '\n",
       "                                     'another time.(Applause)Chris Anderson: '\n",
       "                                     \"It's a deal!(Applause)Al Gore: I want to \"\n",
       "                                     'focus on what many of you have said you '\n",
       "                                     'would like me to elaborate on: What can '\n",
       "                                     'you do about the climate crisis? I want '\n",
       "                                     \"to start with a couple of  I'm going to \"\n",
       "                                     \"show some new images, and I'm going to \"\n",
       "                                     'recapitulate just four or five. Now, the '\n",
       "                                     'slide show. I update the slide show '\n",
       "                                     'every time I give it. I add new images, '\n",
       "                                     'because I learn more about it every time '\n",
       "                                     \"I give it. It's like beach-combing, you \"\n",
       "                                     'know? Every time the tide comes in and '\n",
       "                                     'out, you find some more shells. Just in '\n",
       "                                     'the last two days, we got the new '\n",
       "                                     'temperature records in January. This is '\n",
       "                                     'just for the United States of America. '\n",
       "                                     'Historical average for Januarys is 31 '\n",
       "                                     'degrees; last month was 39.5 '\n",
       "                                     'degrees.Now, I know that you wanted some '\n",
       "                                     'more bad news about the environment  '\n",
       "                                     \"I'm kidding. But these are the \"\n",
       "                                     \"recapitulation slides, and then I'm \"\n",
       "                                     'going to go into new material about what '\n",
       "                                     'you can do. But I wanted to elaborate on '\n",
       "                                     'a couple of these. First of all, this is '\n",
       "                                     \"where we're projected to go with the \"\n",
       "                                     'U.S. contribution to global warming, '\n",
       "                                     'under business as usual. Efficiency in '\n",
       "                                     'end-use electricity and end-use of all '\n",
       "                                     'energy is the low-hanging fruit. '\n",
       "                                     \"Efficiency and conservation  it's not a \"\n",
       "                                     \"cost; it's a profit. The sign is wrong. \"\n",
       "                                     \"It's not negative; it's positive. These \"\n",
       "                                     'are investments that pay for themselves. '\n",
       "                                     'But they are also very effective in '\n",
       "                                     'deflecting our path.Cars and trucks  I '\n",
       "                                     'talked about that in the slideshow, but '\n",
       "                                     'I want you to put it in perspective. '\n",
       "                                     \"It's an easy, visible target of concern \"\n",
       "                                     ' and it should be  but there is more '\n",
       "                                     'global warming pollution that comes from '\n",
       "                                     'buildings than from cars and trucks. '\n",
       "                                     'Cars and trucks are very significant, '\n",
       "                                     'and we have the lowest standards in the '\n",
       "                                     'world. And so we should address that. '\n",
       "                                     \"But it's part of the puzzle. Other \"\n",
       "                                     'transportation efficiency is as '\n",
       "                                     'important as cars and trucks. Renewables '\n",
       "                                     'at the current levels of technological '\n",
       "                                     'efficiency can make this much '\n",
       "                                     'difference. And with what Vinod, and '\n",
       "                                     'John Doerr and others, many of you here '\n",
       "                                     ' there are a lot of people directly '\n",
       "                                     'involved in this  this wedge is going '\n",
       "                                     'to grow much more rapidly than the '\n",
       "                                     'current projection shows it. Carbon '\n",
       "                                     \"Capture and Sequestration  that's what \"\n",
       "                                     'CCS stands for  is likely to become the '\n",
       "                                     'killer app that will enable us to '\n",
       "                                     'continue to use fossil fuels in a way '\n",
       "                                     'that is safe. Not quite there yet. OK. '\n",
       "                                     'Now, what can you do?Reduce emissions in '\n",
       "                                     'your home. Most of these expenditures '\n",
       "                                     'are also profitable. Insulation, better '\n",
       "                                     'design. Buy green electricity where you '\n",
       "                                     'can. I mentioned automobiles  buy a '\n",
       "                                     'hybrid. Use light rail. Figure out some '\n",
       "                                     'of the other options that are much '\n",
       "                                     \"better. It's important.Be a green \"\n",
       "                                     'consumer. You have choices with '\n",
       "                                     'everything you buy, between things that '\n",
       "                                     'have a harsh effect, or a much less '\n",
       "                                     'harsh effect on the global climate '\n",
       "                                     'crisis. Consider this: Make a decision '\n",
       "                                     'to live a carbon-neutral life. Those of '\n",
       "                                     \"you who are good at branding, I'd love \"\n",
       "                                     'to get your advice and help on how to '\n",
       "                                     'say this in a way that connects with the '\n",
       "                                     'most people. It is easier than you '\n",
       "                                     'think. It really is. A lot of us in here '\n",
       "                                     'have made that decision, and it is '\n",
       "                                     'really pretty easy. It means reduce your '\n",
       "                                     'carbon dioxide emissions with the full '\n",
       "                                     'range of choices that you make, and then '\n",
       "                                     'purchase or acquire offsets for the '\n",
       "                                     'remainder that you have not completely '\n",
       "                                     'reduced. And what it means is elaborated '\n",
       "                                     'at climatecrisis.net.There is a carbon '\n",
       "                                     'calculator. Participant Productions '\n",
       "                                     'convened  with my active involvement  '\n",
       "                                     'the leading software writers in the '\n",
       "                                     'world, on this arcane science of carbon '\n",
       "                                     'calculation, to construct a '\n",
       "                                     'consumer-friendly carbon calculator. You '\n",
       "                                     'can very precisely calculate what your '\n",
       "                                     'CO2 emissions are, and then you will be '\n",
       "                                     'given options to reduce. And by the time '\n",
       "                                     'the movie comes out in May, this will be '\n",
       "                                     'updated to 2.0, and we will have '\n",
       "                                     'click-through purchases of offsets.Next, '\n",
       "                                     'consider making your business '\n",
       "                                     'carbon-neutral. Again, some of us have '\n",
       "                                     \"done that, and it's not as hard as you \"\n",
       "                                     'think. Integrate climate solutions into '\n",
       "                                     'all of your innovations, whether you are '\n",
       "                                     'from the technology, or entertainment, '\n",
       "                                     'or design and architecture community. '\n",
       "                                     'Invest sustainably. Majora mentioned '\n",
       "                                     'this. Listen, if you have invested money '\n",
       "                                     'with managers who you compensate on the '\n",
       "                                     \"basis of their annual performance, don't \"\n",
       "                                     'ever again complain about quarterly '\n",
       "                                     'report CEO management. Over time, people '\n",
       "                                     'do what you pay them to do. And if they '\n",
       "                                     \"judge how much they're going to get paid \"\n",
       "                                     \"on your capital that they've invested, \"\n",
       "                                     \"based on the short-term returns, you're \"\n",
       "                                     'going to get short-term decisions. A lot '\n",
       "                                     'more to be said about that.Become a '\n",
       "                                     'catalyst of change. Teach others, learn '\n",
       "                                     'about it, talk about it. The movie is a '\n",
       "                                     'movie version of the slideshow I gave '\n",
       "                                     \"two nights ago, except it's a lot more \"\n",
       "                                     'entertaining. And it comes out in May. '\n",
       "                                     'Many of you here have the opportunity to '\n",
       "                                     'ensure that a lot of people see it. '\n",
       "                                     'Consider sending somebody to Nashville. '\n",
       "                                     'Pick well. And I am personally going to '\n",
       "                                     'train people to give this slideshow  '\n",
       "                                     're-purposed, with some of the personal '\n",
       "                                     'stories obviously replaced with a '\n",
       "                                     \"generic approach, and it's not just the \"\n",
       "                                     \"slides, it's what they mean. And it's \"\n",
       "                                     \"how they link together. And so I'm going \"\n",
       "                                     'to be conducting a course this summer '\n",
       "                                     'for a group of people that are nominated '\n",
       "                                     'by different folks to come and then give '\n",
       "                                     'it en masse, in communities all across '\n",
       "                                     \"the country, and we're going to update \"\n",
       "                                     'the slideshow for all of them every '\n",
       "                                     'single week, to keep it right on the '\n",
       "                                     'cutting edge. Working with Larry Lessig, '\n",
       "                                     'it will be, somewhere in that process, '\n",
       "                                     'posted with tools and limited-use '\n",
       "                                     'copyrights, so that young people can '\n",
       "                                     'remix it and do it in their own '\n",
       "                                     'way.(Applause)Where did anybody get the '\n",
       "                                     \"idea that you ought to stay arm's length \"\n",
       "                                     \"from politics? It doesn't mean that if \"\n",
       "                                     \"you're a Republican, that I'm trying to \"\n",
       "                                     'convince you to be a Democrat. We need '\n",
       "                                     'Republicans as well. This used to be a '\n",
       "                                     'bipartisan issue, and I know that in '\n",
       "                                     'this group it really is. Become '\n",
       "                                     'politically active. Make our democracy '\n",
       "                                     \"work the way it's supposed to work. \"\n",
       "                                     'Support the idea of capping carbon '\n",
       "                                     'dioxide emissions  global warming '\n",
       "                                     \"pollution  and trading it. Here's why: \"\n",
       "                                     'as long as the United States is out of '\n",
       "                                     \"the world system, it's not a closed \"\n",
       "                                     'system. Once it becomes a closed system, '\n",
       "                                     'with U.S. participation, then everybody '\n",
       "                                     \"who's on a board of directors  how many \"\n",
       "                                     'people here serve on the board of '\n",
       "                                     \"directors of a corporation? Once it's a \"\n",
       "                                     'closed system, you will have legal '\n",
       "                                     'liability if you do not urge your CEO to '\n",
       "                                     'get the maximum income from reducing and '\n",
       "                                     'trading the carbon emissions that can be '\n",
       "                                     'avoided. The market will work to solve '\n",
       "                                     'this problem  if we can accomplish '\n",
       "                                     'this. Help with the mass persuasion '\n",
       "                                     'campaign that will start this spring. We '\n",
       "                                     'have to change the minds of the American '\n",
       "                                     'people. Because presently, the '\n",
       "                                     'politicians do not have permission to do '\n",
       "                                     'what needs to be done.And in our modern '\n",
       "                                     'country, the role of logic and reason no '\n",
       "                                     'longer includes mediating between wealth '\n",
       "                                     \"and power the way it once did. It's now \"\n",
       "                                     'repetition of short, hot-button, '\n",
       "                                     '30-second, 28-second television ads. We '\n",
       "                                     \"have to buy a lot of those ads. Let's \"\n",
       "                                     're-brand global warming, as many of you '\n",
       "                                     'have suggested. I like \"climate crisis\" '\n",
       "                                     'instead of \"climate collapse,\" but '\n",
       "                                     'again, those of you who are good at '\n",
       "                                     'branding, I need your help on this. '\n",
       "                                     \"Somebody said the test we're facing now, \"\n",
       "                                     'a scientist told me, is whether the '\n",
       "                                     'combination of an opposable thumb and a '\n",
       "                                     'neocortex is a viable '\n",
       "                                     \"combination.(Laughter)That's really \"\n",
       "                                     \"true.I said the other night, and I'll \"\n",
       "                                     'repeat now: this is not a political '\n",
       "                                     'issue. Again, the Republicans here  '\n",
       "                                     \"this shouldn't be partisan. You have \"\n",
       "                                     'more influence than some of us who are '\n",
       "                                     'Democrats do. This is an opportunity. '\n",
       "                                     'Not just this, but connected to the '\n",
       "                                     'ideas that are here, to bring more '\n",
       "                                     'coherence to them. We are one.Thank you '\n",
       "                                     'very much, I appreciate it.(Applause)',\n",
       "                           'speaker_occupation': 'Climate advocate',\n",
       "                           'title': 'Averting the climate crisis',\n",
       "                           'url': 'https://www.ted.com/talks/al_gore_on_averting_climate_crisis\\n'},\n",
       "              'score': 0.714085639,\n",
       "              'values': []},\n",
       "             {'id': '3a3bcaa4-2e2b-4fa9-ba89-8e4f558270f4',\n",
       "              'metadata': {'chunk_num': 44.0,\n",
       "                           'description': 'With the same humor and humanity he '\n",
       "                                          'exuded in \"An Inconvenient Truth,\" '\n",
       "                                          'Al Gore spells out 15 ways that '\n",
       "                                          'individuals can address climate '\n",
       "                                          'change immediately, from buying a '\n",
       "                                          'hybrid to inventing a new, hotter '\n",
       "                                          'brand name for global warming.',\n",
       "                           'main_speaker': 'Al Gore',\n",
       "                           'name': 'Al Gore: Averting the climate crisis',\n",
       "                           'row': 1.0,\n",
       "                           'source': \"Thank you so much, Chris. And it's truly \"\n",
       "                                     'a great honor to have the opportunity to '\n",
       "                                     \"come to this stage twice; I'm extremely \"\n",
       "                                     'grateful. I have been blown away by this '\n",
       "                                     'conference, and I want to thank all of '\n",
       "                                     'you for the many nice comments about '\n",
       "                                     'what I had to say the other night. And I '\n",
       "                                     'say that sincerely, partly because (Mock '\n",
       "                                     'sob) I need that.(Laughter)Put '\n",
       "                                     'yourselves in my position.(Laughter)I '\n",
       "                                     'flew on Air Force Two for eight '\n",
       "                                     'years.(Laughter)Now I have to take off '\n",
       "                                     'my shoes or boots to get on an '\n",
       "                                     \"airplane!(Laughter)(Applause)I'll tell \"\n",
       "                                     'you one quick story to illustrate what '\n",
       "                                     \"that's been like for me.(Laughter)It's a \"\n",
       "                                     'true story  every bit of this is '\n",
       "                                     'true.Soon after Tipper and I left the  '\n",
       "                                     '(Mock sob) White House (Laughter)we '\n",
       "                                     'were driving from our home in Nashville '\n",
       "                                     'to a little farm we have 50 miles east '\n",
       "                                     'of Nashville. Driving '\n",
       "                                     'ourselves.(Laughter)I know it sounds '\n",
       "                                     'like a little thing to you, but '\n",
       "                                     '(Laughter)I looked in the rear-view '\n",
       "                                     'mirror and all of a sudden it just hit '\n",
       "                                     'me. There was no motorcade back '\n",
       "                                     \"there.(Laughter)You've heard of phantom \"\n",
       "                                     'limb pain?(Laughter)This was a rented '\n",
       "                                     'Ford Taurus.(Laughter)It was dinnertime, '\n",
       "                                     'and we started looking for a place to '\n",
       "                                     'eat. We were on I-40. We got to Exit '\n",
       "                                     '238, Lebanon, Tennessee. We got off the '\n",
       "                                     \"exit, we found a Shoney's restaurant. \"\n",
       "                                     'Low-cost family restaurant chain, for '\n",
       "                                     \"those of you who don't know it. We went \"\n",
       "                                     'in and sat down at the booth, and the '\n",
       "                                     'waitress came over, made a big commotion '\n",
       "                                     'over Tipper.(Laughter)She took our '\n",
       "                                     'order, and then went to the couple in '\n",
       "                                     'the booth next to us, and she lowered '\n",
       "                                     'her voice so much, I had to really '\n",
       "                                     'strain to hear what she was saying. And '\n",
       "                                     'she said \"Yes, that\\'s former Vice '\n",
       "                                     'President Al Gore and his wife, Tipper.\" '\n",
       "                                     'And the man said, \"He\\'s come down a '\n",
       "                                     \"long way, hasn't \"\n",
       "                                     'he?\"(Laughter)(Applause)There\\'s been '\n",
       "                                     'kind of a series of '\n",
       "                                     'epiphanies.(Laughter)The very next day, '\n",
       "                                     'continuing the totally true story, I got '\n",
       "                                     'on a G-V to fly to Africa to make a '\n",
       "                                     'speech in Nigeria, in the city of Lagos, '\n",
       "                                     'on the topic of energy. And I began the '\n",
       "                                     'speech by telling them the story of what '\n",
       "                                     'had just happened the day before in '\n",
       "                                     'Nashville. And I told it pretty much the '\n",
       "                                     \"same way I've just shared it with you: \"\n",
       "                                     'Tipper and I were driving ourselves, '\n",
       "                                     \"Shoney's, low-cost family restaurant \"\n",
       "                                     'chain, what the man said  they laughed. '\n",
       "                                     'I gave my speech, then went back out to '\n",
       "                                     'the airport to fly back home. I fell '\n",
       "                                     'asleep on the plane until, during the '\n",
       "                                     'middle of the night, we landed on the '\n",
       "                                     'Azores Islands for refueling. I woke up, '\n",
       "                                     'they opened the door, I went out to get '\n",
       "                                     'some fresh air, and I looked, and there '\n",
       "                                     'was a man running across the runway. And '\n",
       "                                     'he was waving a piece of paper, and he '\n",
       "                                     'was yelling, \"Call Washington! Call '\n",
       "                                     'Washington!\" And I thought to myself, in '\n",
       "                                     'the middle of the night, in the middle '\n",
       "                                     'of the Atlantic, what in the world could '\n",
       "                                     'be wrong in Washington? Then I '\n",
       "                                     'remembered it could be a bunch of '\n",
       "                                     'things.(Laughter)But what it turned out '\n",
       "                                     'to be, was that my staff was extremely '\n",
       "                                     'upset because one of the wire services '\n",
       "                                     'in Nigeria had already written a story '\n",
       "                                     'about my speech, and it had already been '\n",
       "                                     'printed in cities all across the United '\n",
       "                                     'States of America. It was printed in '\n",
       "                                     'Monterey, I checked.(Laughter)And the '\n",
       "                                     'story began, \"Former Vice President Al '\n",
       "                                     'Gore announced in Nigeria yesterday,\" '\n",
       "                                     \"quote: 'My wife Tipper and I have opened \"\n",
       "                                     'a low-cost family restaurant\\'\" '\n",
       "                                     '(Laughter)\"\\'named Shoney\\'s, and we '\n",
       "                                     'are running it '\n",
       "                                     'ourselves.\\'\"(Laughter)Before I could '\n",
       "                                     'get back to U.S. soil, David Letterman '\n",
       "                                     'and Jay Leno had already started in on  '\n",
       "                                     \"one of them had me in a big white chef's \"\n",
       "                                     'hat, Tipper was saying, \"One more burger '\n",
       "                                     'with fries!\"(Laughter)Three days later, '\n",
       "                                     'I got a nice, long, handwritten letter '\n",
       "                                     'from my friend and partner and colleague '\n",
       "                                     'Bill Clinton, saying, \"Congratulations '\n",
       "                                     'on the new restaurant, Al!\"(Laughter)We '\n",
       "                                     \"like to celebrate each other's successes \"\n",
       "                                     'in life.(Laughter)I was going to talk '\n",
       "                                     'about information ecology. But I was '\n",
       "                                     'thinking that, since I plan to make a '\n",
       "                                     'lifelong habit of coming back to TED, '\n",
       "                                     'that maybe I could talk about that '\n",
       "                                     'another time.(Applause)Chris Anderson: '\n",
       "                                     \"It's a deal!(Applause)Al Gore: I want to \"\n",
       "                                     'focus on what many of you have said you '\n",
       "                                     'would like me to elaborate on: What can '\n",
       "                                     'you do about the climate crisis? I want '\n",
       "                                     \"to start with a couple of  I'm going to \"\n",
       "                                     \"show some new images, and I'm going to \"\n",
       "                                     'recapitulate just four or five. Now, the '\n",
       "                                     'slide show. I update the slide show '\n",
       "                                     'every time I give it. I add new images, '\n",
       "                                     'because I learn more about it every time '\n",
       "                                     \"I give it. It's like beach-combing, you \"\n",
       "                                     'know? Every time the tide comes in and '\n",
       "                                     'out, you find some more shells. Just in '\n",
       "                                     'the last two days, we got the new '\n",
       "                                     'temperature records in January. This is '\n",
       "                                     'just for the United States of America. '\n",
       "                                     'Historical average for Januarys is 31 '\n",
       "                                     'degrees; last month was 39.5 '\n",
       "                                     'degrees.Now, I know that you wanted some '\n",
       "                                     'more bad news about the environment  '\n",
       "                                     \"I'm kidding. But these are the \"\n",
       "                                     \"recapitulation slides, and then I'm \"\n",
       "                                     'going to go into new material about what '\n",
       "                                     'you can do. But I wanted to elaborate on '\n",
       "                                     'a couple of these. First of all, this is '\n",
       "                                     \"where we're projected to go with the \"\n",
       "                                     'U.S. contribution to global warming, '\n",
       "                                     'under business as usual. Efficiency in '\n",
       "                                     'end-use electricity and end-use of all '\n",
       "                                     'energy is the low-hanging fruit. '\n",
       "                                     \"Efficiency and conservation  it's not a \"\n",
       "                                     \"cost; it's a profit. The sign is wrong. \"\n",
       "                                     \"It's not negative; it's positive. These \"\n",
       "                                     'are investments that pay for themselves. '\n",
       "                                     'But they are also very effective in '\n",
       "                                     'deflecting our path.Cars and trucks  I '\n",
       "                                     'talked about that in the slideshow, but '\n",
       "                                     'I want you to put it in perspective. '\n",
       "                                     \"It's an easy, visible target of concern \"\n",
       "                                     ' and it should be  but there is more '\n",
       "                                     'global warming pollution that comes from '\n",
       "                                     'buildings than from cars and trucks. '\n",
       "                                     'Cars and trucks are very significant, '\n",
       "                                     'and we have the lowest standards in the '\n",
       "                                     'world. And so we should address that. '\n",
       "                                     \"But it's part of the puzzle. Other \"\n",
       "                                     'transportation efficiency is as '\n",
       "                                     'important as cars and trucks. Renewables '\n",
       "                                     'at the current levels of technological '\n",
       "                                     'efficiency can make this much '\n",
       "                                     'difference. And with what Vinod, and '\n",
       "                                     'John Doerr and others, many of you here '\n",
       "                                     ' there are a lot of people directly '\n",
       "                                     'involved in this  this wedge is going '\n",
       "                                     'to grow much more rapidly than the '\n",
       "                                     'current projection shows it. Carbon '\n",
       "                                     \"Capture and Sequestration  that's what \"\n",
       "                                     'CCS stands for  is likely to become the '\n",
       "                                     'killer app that will enable us to '\n",
       "                                     'continue to use fossil fuels in a way '\n",
       "                                     'that is safe. Not quite there yet. OK. '\n",
       "                                     'Now, what can you do?Reduce emissions in '\n",
       "                                     'your home. Most of these expenditures '\n",
       "                                     'are also profitable. Insulation, better '\n",
       "                                     'design. Buy green electricity where you '\n",
       "                                     'can. I mentioned automobiles  buy a '\n",
       "                                     'hybrid. Use light rail. Figure out some '\n",
       "                                     'of the other options that are much '\n",
       "                                     \"better. It's important.Be a green \"\n",
       "                                     'consumer. You have choices with '\n",
       "                                     'everything you buy, between things that '\n",
       "                                     'have a harsh effect, or a much less '\n",
       "                                     'harsh effect on the global climate '\n",
       "                                     'crisis. Consider this: Make a decision '\n",
       "                                     'to live a carbon-neutral life. Those of '\n",
       "                                     \"you who are good at branding, I'd love \"\n",
       "                                     'to get your advice and help on how to '\n",
       "                                     'say this in a way that connects with the '\n",
       "                                     'most people. It is easier than you '\n",
       "                                     'think. It really is. A lot of us in here '\n",
       "                                     'have made that decision, and it is '\n",
       "                                     'really pretty easy. It means reduce your '\n",
       "                                     'carbon dioxide emissions with the full '\n",
       "                                     'range of choices that you make, and then '\n",
       "                                     'purchase or acquire offsets for the '\n",
       "                                     'remainder that you have not completely '\n",
       "                                     'reduced. And what it means is elaborated '\n",
       "                                     'at climatecrisis.net.There is a carbon '\n",
       "                                     'calculator. Participant Productions '\n",
       "                                     'convened  with my active involvement  '\n",
       "                                     'the leading software writers in the '\n",
       "                                     'world, on this arcane science of carbon '\n",
       "                                     'calculation, to construct a '\n",
       "                                     'consumer-friendly carbon calculator. You '\n",
       "                                     'can very precisely calculate what your '\n",
       "                                     'CO2 emissions are, and then you will be '\n",
       "                                     'given options to reduce. And by the time '\n",
       "                                     'the movie comes out in May, this will be '\n",
       "                                     'updated to 2.0, and we will have '\n",
       "                                     'click-through purchases of offsets.Next, '\n",
       "                                     'consider making your business '\n",
       "                                     'carbon-neutral. Again, some of us have '\n",
       "                                     \"done that, and it's not as hard as you \"\n",
       "                                     'think. Integrate climate solutions into '\n",
       "                                     'all of your innovations, whether you are '\n",
       "                                     'from the technology, or entertainment, '\n",
       "                                     'or design and architecture community. '\n",
       "                                     'Invest sustainably. Majora mentioned '\n",
       "                                     'this. Listen, if you have invested money '\n",
       "                                     'with managers who you compensate on the '\n",
       "                                     \"basis of their annual performance, don't \"\n",
       "                                     'ever again complain about quarterly '\n",
       "                                     'report CEO management. Over time, people '\n",
       "                                     'do what you pay them to do. And if they '\n",
       "                                     \"judge how much they're going to get paid \"\n",
       "                                     \"on your capital that they've invested, \"\n",
       "                                     \"based on the short-term returns, you're \"\n",
       "                                     'going to get short-term decisions. A lot '\n",
       "                                     'more to be said about that.Become a '\n",
       "                                     'catalyst of change. Teach others, learn '\n",
       "                                     'about it, talk about it. The movie is a '\n",
       "                                     'movie version of the slideshow I gave '\n",
       "                                     \"two nights ago, except it's a lot more \"\n",
       "                                     'entertaining. And it comes out in May. '\n",
       "                                     'Many of you here have the opportunity to '\n",
       "                                     'ensure that a lot of people see it. '\n",
       "                                     'Consider sending somebody to Nashville. '\n",
       "                                     'Pick well. And I am personally going to '\n",
       "                                     'train people to give this slideshow  '\n",
       "                                     're-purposed, with some of the personal '\n",
       "                                     'stories obviously replaced with a '\n",
       "                                     \"generic approach, and it's not just the \"\n",
       "                                     \"slides, it's what they mean. And it's \"\n",
       "                                     \"how they link together. And so I'm going \"\n",
       "                                     'to be conducting a course this summer '\n",
       "                                     'for a group of people that are nominated '\n",
       "                                     'by different folks to come and then give '\n",
       "                                     'it en masse, in communities all across '\n",
       "                                     \"the country, and we're going to update \"\n",
       "                                     'the slideshow for all of them every '\n",
       "                                     'single week, to keep it right on the '\n",
       "                                     'cutting edge. Working with Larry Lessig, '\n",
       "                                     'it will be, somewhere in that process, '\n",
       "                                     'posted with tools and limited-use '\n",
       "                                     'copyrights, so that young people can '\n",
       "                                     'remix it and do it in their own '\n",
       "                                     'way.(Applause)Where did anybody get the '\n",
       "                                     \"idea that you ought to stay arm's length \"\n",
       "                                     \"from politics? It doesn't mean that if \"\n",
       "                                     \"you're a Republican, that I'm trying to \"\n",
       "                                     'convince you to be a Democrat. We need '\n",
       "                                     'Republicans as well. This used to be a '\n",
       "                                     'bipartisan issue, and I know that in '\n",
       "                                     'this group it really is. Become '\n",
       "                                     'politically active. Make our democracy '\n",
       "                                     \"work the way it's supposed to work. \"\n",
       "                                     'Support the idea of capping carbon '\n",
       "                                     'dioxide emissions  global warming '\n",
       "                                     \"pollution  and trading it. Here's why: \"\n",
       "                                     'as long as the United States is out of '\n",
       "                                     \"the world system, it's not a closed \"\n",
       "                                     'system. Once it becomes a closed system, '\n",
       "                                     'with U.S. participation, then everybody '\n",
       "                                     \"who's on a board of directors  how many \"\n",
       "                                     'people here serve on the board of '\n",
       "                                     \"directors of a corporation? Once it's a \"\n",
       "                                     'closed system, you will have legal '\n",
       "                                     'liability if you do not urge your CEO to '\n",
       "                                     'get the maximum income from reducing and '\n",
       "                                     'trading the carbon emissions that can be '\n",
       "                                     'avoided. The market will work to solve '\n",
       "                                     'this problem  if we can accomplish '\n",
       "                                     'this. Help with the mass persuasion '\n",
       "                                     'campaign that will start this spring. We '\n",
       "                                     'have to change the minds of the American '\n",
       "                                     'people. Because presently, the '\n",
       "                                     'politicians do not have permission to do '\n",
       "                                     'what needs to be done.And in our modern '\n",
       "                                     'country, the role of logic and reason no '\n",
       "                                     'longer includes mediating between wealth '\n",
       "                                     \"and power the way it once did. It's now \"\n",
       "                                     'repetition of short, hot-button, '\n",
       "                                     '30-second, 28-second television ads. We '\n",
       "                                     \"have to buy a lot of those ads. Let's \"\n",
       "                                     're-brand global warming, as many of you '\n",
       "                                     'have suggested. I like \"climate crisis\" '\n",
       "                                     'instead of \"climate collapse,\" but '\n",
       "                                     'again, those of you who are good at '\n",
       "                                     'branding, I need your help on this. '\n",
       "                                     \"Somebody said the test we're facing now, \"\n",
       "                                     'a scientist told me, is whether the '\n",
       "                                     'combination of an opposable thumb and a '\n",
       "                                     'neocortex is a viable '\n",
       "                                     \"combination.(Laughter)That's really \"\n",
       "                                     \"true.I said the other night, and I'll \"\n",
       "                                     'repeat now: this is not a political '\n",
       "                                     'issue. Again, the Republicans here  '\n",
       "                                     \"this shouldn't be partisan. You have \"\n",
       "                                     'more influence than some of us who are '\n",
       "                                     'Democrats do. This is an opportunity. '\n",
       "                                     'Not just this, but connected to the '\n",
       "                                     'ideas that are here, to bring more '\n",
       "                                     'coherence to them. We are one.Thank you '\n",
       "                                     'very much, I appreciate it.(Applause)',\n",
       "                           'speaker_occupation': 'Climate advocate',\n",
       "                           'title': 'Averting the climate crisis',\n",
       "                           'url': 'https://www.ted.com/talks/al_gore_on_averting_climate_crisis\\n'},\n",
       "              'score': 0.714085639,\n",
       "              'values': []}],\n",
       " 'namespace': 'first_split',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the namespace\n",
    "john = [t for t in users if t.get('name') == 'John'][0]\n",
    "john_query_vector = john['vector_query']\n",
    "john_namespace = john['namespace'] \n",
    "index.query(vector=john_query_vector, top_k=2, include_metadata=True, namespace=john_namespace) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBb0lLb1aikc"
   },
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oykb4AVEGOGr"
   },
   "source": [
    "Now that we have set up our namespaces, we can prepare our RAG pipeline. We will do so, using Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy7TxVjePRKY"
   },
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "y0x1uf06EsXZ"
   },
   "outputs": [],
   "source": [
    "# Create vectorstore\n",
    "# embed = embedding=OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "embed = embedding= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vectorstore = PineconeVectorStore(index_name=index_name,\n",
    "                                  namespace=\"main\",\n",
    "                                  embedding=embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvcx0tsIIOCS"
   },
   "source": [
    "In this retrieval step, you can chose between Open AI or Groq. For Groq, create a `GROQ_API_KEY` which allow you to use some models like llama or mistral for free. We will also add some memory, which allow to keep track of the QA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gjrtn8aDts1k"
   },
   "outputs": [],
   "source": [
    "# Retrieval\n",
    "\n",
    "\n",
    "# # Chat completion llm wit Groq\n",
    "# GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "# llm = ChatGroq(groq_api_key=GROQ_API_KEY,\n",
    "#                model_name=\"llama3-8b-8192\",\n",
    "#                temperature=0.0,\n",
    "#                max_tokens=512)\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI  # Import the Google Generative AI model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "# Conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(memory_key='chat_history',k=5,return_messages=True)\n",
    "\n",
    "# Retrieval qa chain\n",
    "qa_db = RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",retriever=vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrjEobt6JDaB"
   },
   "source": [
    "## Augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMy7o9vAKNGr"
   },
   "source": [
    "We are going to use a slightly modified prompt template. First we download the react template, which is a common template using toools and agents and then we will add the instruction of in which tool to look up first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G84UB4TdOaTz"
   },
   "source": [
    "A collection of templates can be found in the [langchain hub](https://smith.langchain.com/hub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nt_x7n23JKit",
    "outputId": "a1cace5f-829b-4e7e-8d68-67d5d7fd107c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CmJ8bCoN7zq"
   },
   "source": [
    "Now we will replace this line:\n",
    "\n",
    "`Action: the action to take, should be one of [{tool_names}]`\n",
    "\n",
    "By this line:\n",
    "\n",
    "`Action: the action to take, should be one of [{tool_names}]. Always look first in Pinecone Document Store`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ybnrDWgibPgy"
   },
   "outputs": [],
   "source": [
    "# Set prompt template\n",
    "\n",
    "template= '''\n",
    "          Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "          {tools}\n",
    "\n",
    "          Use the following format:\n",
    "\n",
    "          Question: the input question you must answer\n",
    "          Thought: you should always think about what to do\n",
    "          Action: the action to take, should be one of [{tool_names}]. Always look first in Pinecone Document Store if not then use the tool\n",
    "          Action Input: the input to the action\n",
    "          Observation: the result of the action\n",
    "          ... (this Thought/Action/Action Input/Observation can repeat 2 times)\n",
    "          Thought: I now know the final answer\n",
    "          Final Answer: the final answer to the original input question\n",
    "\n",
    "          Begin!\n",
    "\n",
    "          Question: {input}\n",
    "          Thought:{agent_scratchpad}\n",
    "          '''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ7UC5I7PXa0"
   },
   "source": [
    "## Generation with Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kr2ckRgNP1Ne"
   },
   "source": [
    "We are going to set up 2 tools for our agent:\n",
    "\n",
    "- Tavily Search API: Tavily search over several sources like Bing or Google and returns the most relevant content. It offers 1000 API calls per month for free.\n",
    "\n",
    "- Vectorstore: Our vector store will be used to look for the information first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "hX7Ur-nQPb6q"
   },
   "outputs": [],
   "source": [
    "# Set up tools and agent\n",
    "import os\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "tavily = TavilySearchResults(max_results=10, tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Pinecone Document Store\",\n",
    "        func = qa_db.run,\n",
    "        description = \"Use it to lookup information from the Pinecone Document Store\"\n",
    "    ),\n",
    "\n",
    "    Tool(\n",
    "        name=\"Tavily\",\n",
    "        func=tavily.run,\n",
    "        description=\"Use this to lookup information from Tavily\",\n",
    "    )\n",
    "] \n",
    "agent = create_react_agent(llm,tools,prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "                        tools=tools,\n",
    "                        agent=agent,\n",
    "                        handle_parsing_errors=True,\n",
    "                        verbose=True,\n",
    "                        memory=conversational_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omGlF1tc7II_"
   },
   "source": [
    "Once everything is set up, we can start making queries and check how the agents behave in terms priorization of agent, search quality and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJcPXgySlquf",
    "outputId": "c6f7d140-61bf-499e-a0f7-e0e49bb53190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find information about UET Lahore in Pakistan. I'll try looking in the Pinecone Document Store first.\n",
      "Action: Pinecone Document Store\n",
      "Action Input: UET Lahore Pakistan\u001b[0m\u001b[36;1m\u001b[1;3mI'm sorry, but the provided context doesn't mention anything about UET Lahore Pakistan. I can't provide information about this topic. \n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: Since the Pinecone Document Store doesn't have information, I'll try using Tavily.\n",
      "Action: Tavily\n",
      "Action Input: What is UET Lahore in Pakistan?\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://en.wikipedia.org/wiki/University_of_Engineering_and_Technology,_Lahore', 'content': 'The University of Engineering and Technology, Lahore (UET Lahore) is a public university located in Lahore, Punjab, Pakistan specializing in science, technology, engineering, and mathematics (STEM) subjects. It is the oldest and one of the most selective engineering institutions in Pakistan.Every year around 40,000 candidates appear in ECAT while there are around 3,045 fully subsidized (A1 ...'}, {'url': 'https://www.timeshighereducation.com/world-university-rankings/university-engineering-technology-uet-lahore', 'content': \"UET Lahore was founded in 1921 as Mughalpura Technical College and went through a number of incarnations before being named UET in 1972. The university operates over five campuses within the Punjab region, with the main site in Lahore, and links to 23 research centres. The student population numbers over 11,000 across undergraduate, master's and PhD disciplines. UET offers 92 STEM courses ...\"}, {'url': 'https://www.topuniversities.com/universities/university-engineering-technology-uet-lahore', 'content': 'About University of Engineering & Technology (UET) Lahore The University of Engineering and Technology (main) located in the northern part of Lahore on the historical \"Grand Trunk Road (G.T. Road)\", near the magnificent Shalimar Gardens built during the great Mughal Empire.The institution started its career in 1921 as the \\' Mughalpura ...'}, {'url': 'https://www.uet.edu.pk/', 'content': 'One day international seminar on Environmental Friendly Cement-less Concrete for Future Constructions in Pakistan: Geopolymer Concrete, in UET Lahore. 8 Jul. EVENT. OPENING OF UET SWIMMING POOL AFTER 06 YEARS IN UET LAHORE. ... You can support UET in many ways. You can pay your donations to UET Lahore through our bank account given below. This ...'}, {'url': 'https://tribune.com.pk/story/2351656/lahore-uet-rises-in-global-rankings', 'content': 'The Lahore University of Engineering and Technology (UET) has jumped up 52 places to 324 in the QS World subject rankings in engineering and technology, compared to 376 last year and 401-450 the ...'}, {'url': 'https://www.thenews.com.pk/print/948573-uet-jumps-to-324th-place-in-qs-world-rankings', 'content': 'LAHORE:In the latest QS rankings in Engineering and Technology, the University of Engineering and Technology (UET), Lahore has jumped up by 52 places to 324 in the world, compared to 376 last year ...'}, {'url': 'https://www.thenews.com.pk/print/1053311-uet-world-ranking-improves', 'content': 'March 24, 2023. LAHORE: In the latest 2023 QS rankings in Engineering and Technology, the University of Engineering and Technology (UET), Lahore, has jumped up by 47 places to 279 in the world ...'}, {'url': 'https://en.wikipedia.org/wiki/Rankings_of_universities_in_Pakistan', 'content': 'This article presents an overview of university rankings in Pakistan. Within Pakistan, the Higher Education Commission (HEC) provides official rankings of higher education institutions ... University of The Punjab (#701) and UET, Lahore (#801), . In rankings for 2023, the number increased to 7, with the addition of University of Peshawar (#801'}, {'url': 'https://www.usnews.com/education/best-global-universities/university-of-engineering-technology-lahore-529774', 'content': 'University of Engineering & Technology Lahore Rankings. # 1189. in Best Global Universities (tie) # 390. in Best Global Universities in Asia (tie) # 16. in Best Global Universities in Pakistan.'}, {'url': 'https://admission.uet.edu.pk/', 'content': 'NFC Institute of Engineering and Fertilizer Research Faisalabad\\nGovernment College of Technology, Railway Road, Lahore\\nGovernment College of Technology, Faisalabad\\nSharif College of Engineering & Technology, Raiwind Road, Lahore\\nQuaid-e-Azam College of Engineering and Technology, Sahiwal\\nSwedish College of Engineering & Technology Rahim Yar Khan\\nSir Syed College of Computer Science, Gulberg, Lahore\\nGovernment Swedish Pakistani College of Technology, Gujrat\\nGrafton College, Islamabad\\nAdmission - 2024\\n|  2024\\nDeadline: February 29, 2024\\nToken Price: 2,500 PKR\\nDeadline: October 06, 2023\\n For merit determination, see page-21 of\\nundergraduate prospectus\\nDeadline: January 30, 2024\\nToken Price: 2,000 PKR\\nHow to Register for ECAT-2024\\nGenerate Challan\\nVisit the Generate Challan page and save the PDF with the serial number and token number.\\n                \\n                 2    \\nAt UET, passing criterion in non-PEC accredited programs (Computer Science, Software Engineering, Architecture, City and Regional Planning, Product Industrial Design and Technology) has been waived off.\\n         \\nAt UET, appearing in ECAT is not required for Energy Systems and Management, Business Administration, Business and Information Technology, Food Science & Technology,\\nEnvironmental Science, Mathematics, Chemistry and Physics.\\n                        \\nPassing ECAT (i.e., at least 132 out of 400) is necessary for PEC-accredited programs only.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: The University of Engineering and Technology, Lahore (UET Lahore) is a public university in Lahore, Punjab, Pakistan that specializes in STEM subjects. It was founded in 1921 and is one of the oldest and most selective engineering institutions in the country. It has over 11,000 students across undergraduate, master's, and PhD disciplines. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What is UET Lahore in Pakistan?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7fLQ6u5bPjV",
    "outputId": "10aa2121-1f1a-485e-fcc2-5fcd4412a404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to understand what Optimism on Climate Change means. This seems like a concept that might be better explained by a tool like Tavily. \n",
      "Action: Tavily\n",
      "Action Input: \"What is Optimism on Climate Change?\"\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://environment.harvard.edu/news/choosing-be-optimistic-about-climate-change', 'content': 'Optimism is not just \"a feeling that good things will happen,\" as Oxford Dictionary says. Optimism about climate change is the determination to prevent the worst of its consequences through persistence, collaboration, and creativity. In the words of John Kerry, U.S .Special Envoy for Climate, the world is in \"a terrible fix.\".'}, {'url': 'https://www.hsph.harvard.edu/c-change/climateoptimist/', 'content': \"Welcome to your monthly dose of good news about climate change. Climate optimism isn't about denying what we can see with our own eyes, or ignoring our grief for what we've lost. ... Three Reasons to be Optimistic about Climate Change. 665 Huntington Avenue Building 1, Room 1312 Boston, MA 02115 +1 (617) 4951000.\"}, {'url': 'https://insideclimatenews.org/news/28072024/what-would-it-take-to-restore-our-atmosphere/', 'content': '\"Optimism and hope are muscles we have to exercise,\" climate scientist Rob Jackson says. His new book offers a paradigm for how to think about climate change and the health of the planet.'}, {'url': 'https://www.hsph.harvard.edu/news/hsph-in-the-news/why-we-can-be-optimistic-about-climate-change/', 'content': 'Franck, senior communications strategist at the Center for Climate, Health, and the Global Environment at Harvard Chan School and editor of The Climate Optimist newsletter, made the case for climate optimism in a July 26 interview on CNN. \"We already have the solutions and technologies we need to be successful,\" she said.'}, {'url': 'https://www.newscientist.com/article/mg25133573-200-why-hope-and-optimism-are-crucial-for-fighting-climate-change/', 'content': 'Why hope and optimism are crucial for fighting climate change. CLIMATE change is no longer a future issue or a distant one. It is here now, intensifying extreme weather events, threatening food ...'}, {'url': 'https://yaleclimateconnections.org/2022/04/experts-climate-transformative-but-causes-for-optimism/', 'content': \"It's easy to feel pessimistic when scientists around the world are warning that climate change has advanced so far, it's now inevitable that societies will either transform themselves or be transformed.But as two of the authors of a recent international climate report, we also see reason for optimism.. The latest reports from the Intergovernmental Panel on Climate Change discuss changes ...\"}, {'url': 'https://thebulletin.org/premium/2024-01/why-a-mindset-of-stubborn-optimism-about-the-climate-crisis-is-needed-now-more-than-ever/', 'content': 'When it comes to climate change, there has been dramatic progress towards a number of positive tipping pointssuch as technological improvements in wind and solar power, huge increases in the adoption of electric vehicles and heat pumps, better battery storagethat could combine into a self-reinforcing cascade of positive change. Consequently, there is reason for stubborn optimisma most ...'}, {'url': 'https://www.weforum.org/agenda/2024/01/the-climate-crisis-is-humanity-s-greatest-threat-here-s-why-informed-optimism-is-key-to-unlocking-an-effective-response/', 'content': 'Why informed optimism is key to unlock an effective response to the climate crisis. We are both the species that caused the climate crisis and we are uniquely positioned to respond to avert its worst consequences. Extreme weather, critical changes to Earth systems, biodiversity loss and ecosystem collapse are real, interconnected, mutually ...'}, {'url': 'https://www.ted.com/talks/christiana_figueres_the_case_for_stubborn_optimism_on_climate', 'content': 'The case for stubborn optimism on climate. \"This decade is a moment of choice unlike any we have ever lived,\" says Christiana Figueres, the architect of the historic 2015 Paris Agreement. The daughter of Costa Rica\\'s beloved President Jos Figueres Ferrer, she shares how her father\\'s unwillingness to lose the country he loved taught her how ...'}, {'url': 'https://www.yesmagazine.org/environment/2021/11/05/climate-change-optimism', 'content': \"But the climate fight is a big and complex war that's being carried out on many fronts. Even for experienced climate warriors, it's hard to keep the whole picture in your head at once. The apathy and self-dealing in Glasgow are obvious. What's less obvious are signs of real progress. Here are ten reasons for optimism: 1.\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: Tavily provided a lot of useful information about Optimism on Climate Change, highlighting the importance of persistence, collaboration, and creativity in combating the worst of its effects. It also emphasized the need for informed optimism and the existence of solutions and technologies already available to make a difference. \n",
      "Final Answer: Optimism on Climate Change is not just about hoping for the best, but actively working towards preventing the worst consequences through persistence, collaboration, and creativity. It's about recognizing that we have the solutions and technologies needed to make a difference and staying hopeful that we can achieve a positive outcome. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is Optimism on Climate Change',\n",
       " 'chat_history': [HumanMessage(content='Can you Give me the transcript of Ken Robinson Pinecone Document Store?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to the internet or any external files to find a transcript of Ken Robinson's speech.\"),\n",
       "  HumanMessage(content='How is the CEO of Google give me one Paragraph about him?'),\n",
       "  AIMessage(content='Agent stopped due to iteration limit or time limit.'),\n",
       "  HumanMessage(content='Who is the CEO of Google? Provide one paragraph about him.'),\n",
       "  AIMessage(content='Agent stopped due to iteration limit or time limit.'),\n",
       "  HumanMessage(content='what is Optimism on Climate Change'),\n",
       "  AIMessage(content='I am sorry, I cannot answer your question. I am unable to access the necessary information.'),\n",
       "  HumanMessage(content='What is UET Lahore in Pakistan?'),\n",
       "  AIMessage(content=\"The University of Engineering and Technology, Lahore (UET Lahore) is a public university in Lahore, Punjab, Pakistan that specializes in STEM subjects. It was founded in 1921 and is one of the oldest and most selective engineering institutions in the country. It has over 11,000 students across undergraduate, master's, and PhD disciplines.\")],\n",
       " 'output': \"Optimism on Climate Change is not just about hoping for the best, but actively working towards preventing the worst consequences through persistence, collaboration, and creativity. It's about recognizing that we have the solutions and technologies needed to make a difference and staying hopeful that we can achieve a positive outcome.\"}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"what is Optimism on Climate Change\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enUSCNdko96E",
    "outputId": "ca3c63cc-9f8a-4817-86ce-135c1b1f3414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the transcript of Ken Robinson's speech from the Pinecone Document Store. \n",
      "Action: Pinecone Document Store\n",
      "Action Input:  \"Ken Robinson transcript\"\u001b[0m\u001b[36;1m\u001b[1;3mThe provided text is a part of a speech by Ken Robinson. It describes a critical moment in his life when he received a report stating \"Ben lacks sufficient impetus to achieve anything worthwhile.\" This experience shaped his perspective on potential and self-belief. \n",
      "\n",
      "However, the text doesn't provide the full transcript of his speech. \n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to find the full transcript of Ken Robinson's speech. Since the Pinecone Document Store doesn't have the full transcript, I'll try using Tavily.\n",
      "Action: Tavily\n",
      "Action Input: {\"task\": \"Find the full transcript of Ken Robinson's speech\"}\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'http://speakingfrog.com/?p=1029', 'content': 'Nov 29, 2011  Ken Robinson is speaking on the topic of Changing Paradigms in Education at a ... A full transcript can be found on the RealTimeTranscription.comMissing:  { task : s'}, {'url': 'https://singjupost.com/schools-kill-creativity-sir-ken-robinson-transcript/', 'content': \"Nov 3, 2014  Here is the transcript and summary of Sir Ken Robinson's talk titled Do Schools Kill Creativity. Listen to the MP3 Audio here: TRANSCRIPT:.Missing:  { task : | Show results with:{ task :\"}, {'url': 'https://singjupost.com/sir-ken-robinson-finding-your-element-full-transcript/?singlepage=1', 'content': 'Dec 14, 2020  In this talk, Sir Ken Robinson, offers a guide to finding and being in your element. He provides basic principles and tools to help guide us to\\xa0...Missing:  { task : | Show results with:{ task :'}, {'url': 'https://saintkosmas.org/robinson-do-schools-kill-creativity', 'content': 'Sir Ken Robinson, PhD. Selections from the transcript of his TED talk, \"Do Schools Kill Creativity?\" [video and link to full transcript below].Missing:  s speech }'}, {'url': 'https://www.happyscribe.com/public/ted-talks-daily/do-schools-kill-creativity-sir-ken-robinson', 'content': 'Aug 27, 2020  Transcript and discussion of Do schools kill creativity? | Sir Ken Robinson from TED Talks Daily podcast.Missing:  s | Show results with:s'}, {'url': 'https://www.npr.org/transcripts/351552772?storyId=351552772', 'content': 'Oct 3, 2014  Sir Ken Robinson makes a case for creating an education system that nurtures  rather than stifles  creativity.Missing:  s | Show results with:s'}, {'url': 'https://www.ted.com/talks/sir_ken_robinson_do_schools_kill_creativity/transcript', 'content': 'Jun 26, 2006  Actually, what I find is, everybody has an interest in education. ... And our task is to educate ...Duration: 19:11Posted: Jun 26, 2006'}, {'url': 'https://www.studocu.com/fr/document/universite-paris-ii-pantheon-assas/anglais/ken-robinson-video-transcript/20519256', 'content': \"1:47You see, he's right. I mean, there is a major climate crisis, obviously, and I think if people don't believe it, they should get out more. (Laughter) But I\\xa0...\"}, {'url': 'https://www.scribd.com/document/442602523/KEN-Robinson-Speech-transcript-docx', 'content': '3 principles in which human life flourishes  1. humans are naturally different and diversed  3. human life is inheritly creative.'}, {'url': 'https://jamesclear.com/great-speeches/do-schools-kill-creativity-by-ken-robinson', 'content': 'And our task is to educate their whole being, so they can face this future. By the way  we may not see this future, but they will. And our job is to help\\xa0...'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer. The Tavily tool gave me several links that contain the full transcript of Ken Robinson's speech. \n",
      "Final Answer: Here are some links that contain the full transcript of Ken Robinson's speech: \n",
      "* http://speakingfrog.com/?p=1029\n",
      "* https://singjupost.com/schools-kill-creativity-sir-ken-robinson-transcript/\n",
      "* https://singjupost.com/sir-ken-robinson-finding-your-element-full-transcript/?singlepage=1\n",
      "* https://saintkosmas.org/robinson-do-schools-kill-creativity\n",
      "* https://www.happyscribe.com/public/ted-talks-daily/do-schools-kill-creativity-sir-ken-robinson\n",
      "* https://www.npr.org/transcripts/351552772?storyId=351552772\n",
      "* https://www.ted.com/talks/sir_ken_robinson_do_schools_kill_creativity/transcript\n",
      "* https://www.studocu.com/fr/document/universite-paris-ii-pantheon-assas/anglais/ken-robinson-video-transcript/20519256\n",
      "* https://www.scribd.com/document/442602523/KEN-Robinson-Speech-transcript-docx\n",
      "* https://jamesclear.com/great-speeches/do-schools-kill-creativity-by-ken-robinson \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you Give me the transcript of Ken Robinson Pinecone Document Store?',\n",
       " 'chat_history': [HumanMessage(content='How is the CEO of Google give me one Paragraph about him?'),\n",
       "  AIMessage(content='Agent stopped due to iteration limit or time limit.'),\n",
       "  HumanMessage(content='Who is the CEO of Google? Provide one paragraph about him.'),\n",
       "  AIMessage(content='Agent stopped due to iteration limit or time limit.'),\n",
       "  HumanMessage(content='what is Optimism on Climate Change'),\n",
       "  AIMessage(content='I am sorry, I cannot answer your question. I am unable to access the necessary information.'),\n",
       "  HumanMessage(content='What is UET Lahore in Pakistan?'),\n",
       "  AIMessage(content=\"The University of Engineering and Technology, Lahore (UET Lahore) is a public university in Lahore, Punjab, Pakistan that specializes in STEM subjects. It was founded in 1921 and is one of the oldest and most selective engineering institutions in the country. It has over 11,000 students across undergraduate, master's, and PhD disciplines.\"),\n",
       "  HumanMessage(content='what is Optimism on Climate Change'),\n",
       "  AIMessage(content=\"Optimism on Climate Change is not just about hoping for the best, but actively working towards preventing the worst consequences through persistence, collaboration, and creativity. It's about recognizing that we have the solutions and technologies needed to make a difference and staying hopeful that we can achieve a positive outcome.\")],\n",
       " 'output': \"Here are some links that contain the full transcript of Ken Robinson's speech: \\n* http://speakingfrog.com/?p=1029\\n* https://singjupost.com/schools-kill-creativity-sir-ken-robinson-transcript/\\n* https://singjupost.com/sir-ken-robinson-finding-your-element-full-transcript/?singlepage=1\\n* https://saintkosmas.org/robinson-do-schools-kill-creativity\\n* https://www.happyscribe.com/public/ted-talks-daily/do-schools-kill-creativity-sir-ken-robinson\\n* https://www.npr.org/transcripts/351552772?storyId=351552772\\n* https://www.ted.com/talks/sir_ken_robinson_do_schools_kill_creativity/transcript\\n* https://www.studocu.com/fr/document/universite-paris-ii-pantheon-assas/anglais/ken-robinson-video-transcript/20519256\\n* https://www.scribd.com/document/442602523/KEN-Robinson-Speech-transcript-docx\\n* https://jamesclear.com/great-speeches/do-schools-kill-creativity-by-ken-robinson\"}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Can you Give me the transcript of Ken Robinson Pinecone Document Store?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czu_mPH0r4cD",
    "outputId": "682bb84a-e050-43ff-cdf3-e982868814a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to check if Dan Gilbert has given a TEDx talk. I can use Tavily to search for information about him. \n",
      "Action: Tavily\n",
      "Action Input: {'query': 'Dan Gilbert TEDx'}\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://tedxasbury.com/08/2013/dan-gilbert-why-we-make-bad-decisions/', 'content': 'Dan Gilbert, author of Stumbling on Happiness and a noted behavorial psychologist, explains in his TED talk how we are terribly accurate in making poor decisions. Due to an array of cognitive biases and \"lazy thinking\", on a daily basis people approach their lives with a faulty toolkit.'}, {'url': 'https://www.ted.com/talks/dan_gilbert_the_surprising_science_of_happiness', 'content': 'The surprising science of happiness. 20,775,190 views |. Dan Gilbert |. TED2004.  February 2004. Read transcript. Dan Gilbert, author of \"Stumbling on Happiness,\" challenges the idea that we\\'ll be miserable if we don\\'t get what we want. Our \"psychological immune system\" lets us feel truly happy even when things don\\'t go as planned.'}, {'url': 'https://premierespeakers.com/speakers/dan-gilbert', 'content': \"View details for keynote & motivational speaker Dan Gilbert. Speaking fee, bio, contact, and how to book Dan Gilbert for your next event. ... TEDx:It's the end of the world as we know it (and I feel fine) Time 22:48. TED: The Surprising Science of Happiness. Time 21:20. TED: Why we make bad decisions. Time 34:10. Dan Gilbert.\"}, {'url': 'https://blog.ted.com/ten-years-later-dan-gilbert-on-life-after-the-surprising-science-of-happiness/', 'content': 'April 11, 2014 at 3:06 pm EDT. Dan Gilbert gave his first TED Talk in February 2004; The surprising science of happiness was one of the first we ever published, in September 2006. Here, the Harvard psychologist reminisces about the impact of TED, shares some suggestions of useful further reading  and owns up to some mistakes.'}, {'url': 'https://www.ted.com/search?cat=tedx_events&q=dan+gilbert+', 'content': 'Organize a local TEDx event. Rules and resources to help you plan a local TEDx event. Translate. Bring TED to the non-English speaking world ... (JST) TED2014 Simulcast: All-Stars Session 2: Beauty and the Brain Tierney Thys - Marine biologist Dan Gilbert - Psychologist; happiness expert Emily Levine - Philosopher-comic David Brooks ...'}, {'url': 'https://www.youtube.com/watch?v=c-4flnuxNV4', 'content': 'http://www.ted.com Dan Gilbert presents research and data from his exploration of happiness -- sharing some surprising tests and experiments that you can als...'}, {'url': 'https://www.youtube.com/watch?v=4q1dgn_C0AU', 'content': 'http://www.ted.com Dan Gilbert, author of Stumbling on Happiness, challenges the idea that we\\'ll be miserable if we don\\'t get what we want. Our \"psychologica...'}, {'url': 'https://www.npr.org/2012/04/27/151361554/what-makes-us-happy', 'content': \"What Makes Us Happy? Part 3 of the TED Radio Hour episode Our Buggy Brain. Dan Gilbert, author of Stumbling on Happiness, challenges the idea that we'll be miserable if we don't get what we want ...\"}, {'url': 'https://www.youtube.com/watch?v=1Z-5uMdqqPY', 'content': \"Psychologist Daniel Gilbert delves deep into the weird, counterintuitive science of happiness and explains why our minds worry about things we needn't worry ...\"}, {'url': 'http://www.tedxcle.com/dan-gilbert-the-surprising-science-of-happiness/', 'content': \"Dan Gilbert believes that, in our ardent, lifelong pursuit of happiness, most of us have the wrong map. In the same way that optical illusions fool our eyes  and fool everyone's eyes in the same way  Gilbert argues that our brains systematically misjudge what will make us happy.And these quirks in our cognition make humans very poor predictors of our own bliss.\"}]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIs Dan Gilbert a main speaker of TEDx talks? If yes, give me the source of your answer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1612\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1610\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1612\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1621\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1622\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1318\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1311\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1318\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1328\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1318\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1311\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1318\u001b[0m         [\n\u001b[0;32m   1319\u001b[0m             a\n\u001b[0;32m   1320\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1321\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1322\u001b[0m                 color_mapping,\n\u001b[0;32m   1323\u001b[0m                 inputs,\n\u001b[0;32m   1324\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1325\u001b[0m                 run_manager,\n\u001b[0;32m   1326\u001b[0m             )\n\u001b[0;32m   1327\u001b[0m         ]\n\u001b[0;32m   1328\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1346\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1343\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1346\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:463\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m             final_output \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3253\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   3248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3249\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   3250\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3251\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3253\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3240\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   3235\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3236\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   3237\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3238\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3239\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3240\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   3241\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3242\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   3243\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   3244\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3245\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2053\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2052\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 2053\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mnext\u001b[39m, iterator)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2054\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   2055\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3202\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3199\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3200\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 3202\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[0;32m   3203\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1271\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1268\u001b[0m final: Input\n\u001b[0;32m   1269\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ichunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[0;32m   1272\u001b[0m     \u001b[38;5;66;03m# The default implementation of transform is to buffer input and\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;66;03m# then call stream.\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;66;03m# It'll attempt to gather all input into a single chunk using\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m     \u001b[38;5;66;03m# the `+` operator.\u001b[39;00m\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;66;03m# If the input is not addable, then we'll assume that we can\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;66;03m# only operate on the last chunk,\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;66;03m# and we'll iterate until we get to the last chunk.\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[0;32m   1280\u001b[0m         final \u001b[38;5;241m=\u001b[39m ichunk\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5267\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   5262\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   5264\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5265\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   5266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 5267\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   5268\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5269\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5270\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5271\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1289\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1286\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1289\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:373\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    367\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[0;32m    368\u001b[0m         e,\n\u001b[0;32m    369\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[0;32m    370\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    371\u001b[0m         ),\n\u001b[0;32m    372\u001b[0m     )\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:353\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter\u001b[38;5;241m.\u001b[39macquire(blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m             chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_manager\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1019\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._stream\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, **kwargs)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream\u001b[39m(\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    999\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1009\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ChatGenerationChunk]:\n\u001b[0;32m   1010\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m   1011\u001b[0m         messages,\n\u001b[0;32m   1012\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1017\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[1;32m-> 1019\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_generate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m   1026\u001b[0m         _chat_result \u001b[38;5;241m=\u001b[39m _response_to_result(chunk, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:194\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:192\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:176\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:1122\u001b[0m, in \u001b[0;36mGenerativeServiceClient.stream_generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1122\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SONIC LAPTOPS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:174\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[0;32m    171\u001b[0m         result, prefetch_first_result\u001b[38;5;241m=\u001b[39mprefetch_first\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Is Dan Gilbert a main speaker of TEDx talks? If yes, give me the source of your answer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVNAQy_PspP0",
    "outputId": "2015b92e-e856-4a30-a55b-b09d07e46837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should look up information about Dan Gilbert's TEDx talks in the Pinecone Document Store first.\n",
      "Action: Pinecone Document Store\n",
      "Action Input: Dan Gilbert TEDx talks\u001b[0m\u001b[36;1m\u001b[1;3mI'm sorry, but based on the provided context, there is no mention of Dan Gilbert giving a TEDx talk.\u001b[0m\u001b[32;1m\u001b[1;3mAction: Tavily\n",
      "Action Input: Dan Gilbert TEDx talks\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.ted.com/speakers/dan_gilbert', 'content': 'Harvard psychologist Dan Gilbert says our beliefs about what will make us happy are often wrong  a premise he supports with intriguing research, and explains\\xa0...'}, {'url': 'https://blog.ted.com/ten-years-later-dan-gilbert-on-life-after-the-surprising-science-of-happiness/', 'content': 'Dan Gilbert gave his first TED Talk in February 2004; The surprising science of happiness was one of the first we ever published,\\xa0...'}]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The main topic of Dan Gilbert's TEDx talks is the surprising science of happiness.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the main topic of Dan Gilbert TEDx talks?',\n",
       " 'chat_history': [HumanMessage(content='Can you give me one title of a TED talk of Al Gore as main speaker?.                                 Please look in the pinecone document store metadata as it has the title                                 based on the transcripts'),\n",
       "  AIMessage(content='The title of a TED talk by Al Gore as the main speaker is \"The case for optimism on climate change\". Al Gore is a former Vice President of the United States known for his work on environmental issues, particularly climate change.'),\n",
       "  HumanMessage(content=\"Did you find the previous title 'The Case for Optimism on Climate Change' in the Pinecone Document Store?\"),\n",
       "  AIMessage(content=\"Yes, the previous title 'The Case for Optimism on Climate Change' was found in both the Pinecone Document Store and Tavily.\"),\n",
       "  HumanMessage(content='Can you look for a title within the Pinecone Document Store?'),\n",
       "  AIMessage(content='I need more specific details or clarification on the title you are looking for in order to assist you further.'),\n",
       "  HumanMessage(content='Is Dan Gilbert a main speaker of TEDx talks? If yes, give me the source of your answer'),\n",
       "  AIMessage(content='Dan Gilbert is a main speaker of TEDx talks. The source of this information can be found on premierespeakers.com.')],\n",
       " 'output': \"The main topic of Dan Gilbert's TEDx talks is the surprising science of happiness.\"}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is the main topic of Dan Gilbert TEDx talks?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lgo9hYXQmChb",
    "outputId": "7f75a347-06d1-45b0-eebe-3df91704ff5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can you give me one title of a TED talk of Al Gore as main speaker?.                                 Please look in the pinecone document store metadata as it has the title                                 based on the transcripts'),\n",
       "  AIMessage(content='The title of a TED talk by Al Gore as the main speaker is \"The case for optimism on climate change\". Al Gore is a former Vice President of the United States known for his work on environmental issues, particularly climate change.'),\n",
       "  HumanMessage(content=\"Did you find the previous title 'The Case for Optimism on Climate Change' in the Pinecone Document Store?\"),\n",
       "  AIMessage(content=\"Yes, the previous title 'The Case for Optimism on Climate Change' was found in both the Pinecone Document Store and Tavily.\"),\n",
       "  HumanMessage(content='Can you look for a title within the Pinecone Document Store?'),\n",
       "  AIMessage(content='I need more specific details or clarification on the title you are looking for in order to assist you further.'),\n",
       "  HumanMessage(content='Is Dan Gilbert a main speaker of TEDx talks? If yes, give me the source of your answer'),\n",
       "  AIMessage(content='Dan Gilbert is a main speaker of TEDx talks. The source of this information can be found on premierespeakers.com.'),\n",
       "  HumanMessage(content='What is the main topic of Dan Gilbert TEDx talks?'),\n",
       "  AIMessage(content=\"The main topic of Dan Gilbert's TEDx talks is the surprising science of happiness.\")]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "jMiib6omZZo7"
   },
   "outputs": [],
   "source": [
    "agent_executor.memory.clear()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
